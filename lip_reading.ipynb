{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "faG_Pm7iaN0I"
   },
   "outputs": [],
   "source": [
    "#!kill -9 -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3TXSj4g7zITN"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 33
    },
    "id": "PcO0C1IeoZJv",
    "outputId": "7d30fb61-d0da-440e-d58b-348f97782398"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.2.0-rc1'"
      ]
     },
     "execution_count": 2,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ICAyGVkHmLXy"
   },
   "source": [
    "## Get tars and import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 217
    },
    "id": "pOXkW6HJmmwV",
    "outputId": "39928769-9e98-44a1-fd28-51f38a7061d1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2020-03-28 11:37:22--  http://dlib.net/files/shape_predictor_68_face_landmarks.dat.bz2\n",
      "Resolving dlib.net (dlib.net)... 107.180.26.78\n",
      "Connecting to dlib.net (dlib.net)|107.180.26.78|:80... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 64040097 (61M)\n",
      "Saving to: ‘shape_predictor_68_face_landmarks.dat.bz2’\n",
      "\n",
      "shape_predictor_68_ 100%[===================>]  61.07M  18.1MB/s    in 4.9s    \n",
      "\n",
      "2020-03-28 11:37:32 (12.5 MB/s) - ‘shape_predictor_68_face_landmarks.dat.bz2’ saved [64040097/64040097]\n",
      "\n",
      "rm: cannot remove 'shape_predictor_68_face_landmarks.dat.bz2': No such file or directory\n"
     ]
    }
   ],
   "source": [
    "#Dlib predictor download\n",
    "!wget http://dlib.net/files/shape_predictor_68_face_landmarks.dat.bz2\n",
    "!bzip2 -d shape_predictor_68_face_landmarks.dat.bz2 && rm -r shape_predictor_68_face_landmarks.dat.bz2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 170
    },
    "id": "HI5P-tfkmzBn",
    "outputId": "591b5108-0671-45e6-d2c2-7731cdf7121b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting scikit-video\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/b1/a6/c69cad508139a342810ae46e946ebb3256aa6e42f690d901bb68f50582e3/scikit_video-1.1.11-py2.py3-none-any.whl (2.3MB)\n",
      "\u001b[K     |████████████████████████████████| 2.3MB 41kB/s \n",
      "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from scikit-video) (1.18.2)\n",
      "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from scikit-video) (1.4.1)\n",
      "Requirement already satisfied: pillow in /usr/local/lib/python3.6/dist-packages (from scikit-video) (7.0.0)\n",
      "Installing collected packages: scikit-video\n",
      "Successfully installed scikit-video-1.1.11\n"
     ]
    }
   ],
   "source": [
    "!pip install scikit-video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qEr_8Vtdmz-p"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import dlib\n",
    "import math\n",
    "import sys\n",
    "import pickle\n",
    "import argparse\n",
    "import os\n",
    "import skvideo.io"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "A4LoWYBhs5Eh"
   },
   "outputs": [],
   "source": [
    "#!mv s1/video/mpg_6000/ mpg_6000/\n",
    "#!mv s1/video/ video/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6ftV0POaPXlH"
   },
   "source": [
    "## Grid Videos Preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 217
    },
    "id": "kNrwmIIkeOns",
    "outputId": "5b1b86f0-a110-49a1-ccc2-0fc4c273e9e2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2020-03-28 11:37:56--  http://spandh.dcs.shef.ac.uk/gridcorpus/s1/video/s1.mpg_vcd.zip\n",
      "Resolving spandh.dcs.shef.ac.uk (spandh.dcs.shef.ac.uk)... 143.167.8.2\n",
      "Connecting to spandh.dcs.shef.ac.uk (spandh.dcs.shef.ac.uk)|143.167.8.2|:80... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 422746353 (403M) [application/zip]\n",
      "Saving to: ‘s1.mpg_vcd.zip’\n",
      "\n",
      "s1.mpg_vcd.zip      100%[===================>] 403.16M  45.9MB/s    in 9.8s    \n",
      "\n",
      "2020-03-28 11:38:06 (41.2 MB/s) - ‘s1.mpg_vcd.zip’ saved [422746353/422746353]\n",
      "\n",
      "unzip:  cannot find or open s1.mpg_vcd.zip.1, s1.mpg_vcd.zip.1.zip or s1.mpg_vcd.zip.1.ZIP.\n"
     ]
    }
   ],
   "source": [
    "!wget http://spandh.dcs.shef.ac.uk/gridcorpus/s1/video/s1.mpg_vcd.zip\n",
    "!unzip s1.mpg_vcd.zip.1 && rm -r s1.mpg_vcd.zip.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-YVUSOgTnVn0"
   },
   "outputs": [],
   "source": [
    "video_dir='s1/'\n",
    "videos = [video_dir + i for i in os.listdir(video_dir)]\n",
    "videos=sorted(videos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xIeCGQ34NKSJ"
   },
   "outputs": [],
   "source": [
    "videos.remove('s1/Thumbs.db')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uAlgBL8m_F02"
   },
   "outputs": [],
   "source": [
    "name_list=list(set(list(map(lambda x: x[3:5],videos))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2DFWRwCRTlZ2"
   },
   "outputs": [],
   "source": [
    "dummy_videos=list(map(lambda x: x[3:5],videos))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nCJpOEvuSrk6"
   },
   "outputs": [],
   "source": [
    "index_list=[dummy_videos.index(n) for n in name_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "altz4vi9SA3O"
   },
   "outputs": [],
   "source": [
    "index_list.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "mKLmCW0wUVuU",
    "outputId": "85489962-969a-4ef7-baab-5737494d5656"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 58, 122, 180, 240, 304, 362, 426, 488, 552, 616, 680, 744, 808, 872, 936]"
      ]
     },
     "execution_count": 15,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YZfh9nLSU-9a"
   },
   "outputs": [],
   "source": [
    "a=np.asarray(videos)\n",
    "videos=list(a[index_list])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 289
    },
    "id": "dP-mkuffVWyc",
    "outputId": "211089e5-0791-44ba-81fa-6ee5a83c72b9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['s1/bbaf2n.mpg',\n",
       " 's1/bgaa6n.mpg',\n",
       " 's1/braf8n.mpg',\n",
       " 's1/bwaa1s.mpg',\n",
       " 's1/lbad6n.mpg',\n",
       " 's1/lgaf4n.mpg',\n",
       " 's1/lrae2n.mpg',\n",
       " 's1/lwae8n.mpg',\n",
       " 's1/pbac1s.mpg',\n",
       " 's1/pgad8n.mpg',\n",
       " 's1/prac6n.mpg',\n",
       " 's1/pwad2n.mpg',\n",
       " 's1/sbaa4n.mpg',\n",
       " 's1/sgac2n.mpg',\n",
       " 's1/srab1s.mpg',\n",
       " 's1/swab6n.mpg']"
      ]
     },
     "execution_count": 17,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "videos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "58ATbNIJtS6N"
   },
   "outputs": [],
   "source": [
    "#dataset = tf.data.Dataset.from_tensor_slices((videos[:10]))\n",
    "#dataset = dataset.shuffle(10)\n",
    "#dataset = dataset.map(make_mouth_crops, num_parallel_calls=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ewoO6tHgUbuq"
   },
   "outputs": [],
   "source": [
    "#videos = ['id23_vcd_priazn.mpg', 'id2_vcd_swwp2s.mpg']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "U7AGa1AkPp87"
   },
   "source": [
    "## Dlib and lip extract function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 353
    },
    "id": "ns0XWIvXnWuN",
    "outputId": "4d57be6b-5e17-4354-b4fe-cca6f4fc54c4"
   },
   "outputs": [],
   "source": [
    "# Dlib requirements.\n",
    "predictor_path = 'shape_predictor_68_face_landmarks.dat'\n",
    "detector = dlib.get_frontal_face_detector()\n",
    "predictor = dlib.shape_predictor(predictor_path)\n",
    "width_crop_max = 100\n",
    "height_crop_max = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NT70emZOnbPk"
   },
   "outputs": [],
   "source": [
    "def make_mouth_crops(video):\n",
    "  global width_crop_max,height_crop_max,video_pad\n",
    "\n",
    "  inputparameters = {}\n",
    "  outputparameters = {}\n",
    "  reader = skvideo.io.FFmpegReader(video, inputdict=inputparameters, outputdict=outputparameters)\n",
    "  video_shape = reader.getShape()\n",
    "  (num_frames, h, w, c) = video_shape\n",
    "\n",
    "  max_counter = 150\n",
    "  total_num_frames = int(video_shape[0])\n",
    "  num_frames = min(total_num_frames,max_counter)\n",
    "  counter = 0\n",
    "\n",
    "  out_frame=[]\n",
    "\n",
    "\n",
    "\n",
    "  # Loop over all frames.\n",
    "  for frame in reader.nextFrame():\n",
    "    #print('frame_shape:', frame.shape)\n",
    "    # Process the video and extract the frames up to a certain number and then stop processing.\n",
    "    #if counter > num_frames:\n",
    "      #break\n",
    "    # Detection of the frame\n",
    "    detections = detector(frame, 1)\n",
    "    # 20 mark for mouth\n",
    "    marks = np.zeros((2, 20))\n",
    "    # All unnormalized face features.\n",
    "\n",
    "    Features_Abnormal = np.zeros((190, 1))\n",
    "\n",
    "    # If the face is detected.\n",
    "    #print(len(detections))\n",
    "\n",
    "    if len(detections) > 0:\n",
    "      # Shape of the face.\n",
    "      shape = predictor(frame, detections[0]) #single face considered \n",
    "      co = 0\n",
    "      # Specific for the mouth.\n",
    "      for ii in range(48, 68):\n",
    "        \"\"\"\n",
    "        This for loop is going over all mouth-related features.\n",
    "        X and Y coordinates are extracted and stored separately.\n",
    "        \"\"\"\n",
    "        X = shape.part(ii)\n",
    "        A = (X.x, X.y)\n",
    "        marks[0, co] = X.x\n",
    "        marks[1, co] = X.y\n",
    "        co += 1\n",
    "\n",
    "      # Get the extreme points(top-left & bottom-right)\n",
    "      X_left, Y_left, X_right, Y_right = [int(np.amin(marks, axis=1)[0]), int(np.amin(marks, axis=1)[1]),\n",
    "                                          int(np.amax(marks, axis=1)[0]),\n",
    "                                          int(np.amax(marks, axis=1)[1])]\n",
    "      # Find the center of the mouth.\n",
    "      X_center = (X_left + X_right) / 2.0\n",
    "      Y_center = (Y_left + Y_right) / 2.0\n",
    "\n",
    "      # Make a boarder for cropping.\n",
    "      border = 15\n",
    "      X_left_new = X_left - border\n",
    "      Y_left_new = Y_left - border\n",
    "      X_right_new = X_right + border\n",
    "      Y_right_new = Y_right + border\n",
    "\n",
    "      # Width and height for cropping(before and after considering the border).\n",
    "      width_new = X_right_new - X_left_new\n",
    "      height_new = Y_right_new - Y_left_new\n",
    "      width_current = X_right - X_left\n",
    "      height_current = Y_right - Y_left\n",
    "\n",
    "\n",
    "      # Determine the cropping rectangle dimensions(the main purpose is to have a fixed area).\n",
    "      if width_crop_max == 0 and height_crop_max == 0:\n",
    "        width_crop_max = width_new\n",
    "        height_crop_max = height_new\n",
    "      else:\n",
    "        width_crop_max += 1.5 * np.maximum(width_current - width_crop_max, 0)\n",
    "        height_crop_max += 1.5 * np.maximum(height_current - height_crop_max, 0)\n",
    "\n",
    "      # # # Uncomment if the lip area is desired to be rectangular # # # #\n",
    "      #########################################################\n",
    "      # Find the cropping points(top-left and bottom-right).\n",
    "      X_left_crop = int(X_center - width_crop_max / 2.0)\n",
    "      X_right_crop = int(X_center + width_crop_max / 2.0)\n",
    "      Y_left_crop = int(Y_center - height_crop_max / 2.0)\n",
    "      Y_right_crop = int(Y_center + height_crop_max / 2.0)\n",
    "\n",
    "\n",
    "\n",
    "      if X_left_crop >= 0 and Y_left_crop >= 0 and X_right_crop < w and Y_right_crop < h:\n",
    "        mouth = frame[Y_left_crop:Y_right_crop, X_left_crop:X_right_crop, :]\n",
    "        #cv2.imwrite(mouth_destination_path + '/' + 'frame' + '_' + str(counter) + '.png', mouth)\n",
    "        out_frame.append(mouth.T)\n",
    "\n",
    "      else:\n",
    "        cv2.putText(frame, 'NA. ', (30, 30), font, 1, (0, 255, 255), 2) #Check in LRS\n",
    "\n",
    "    else:\n",
    "      #cv2.putText(frame, 'NA. ', (30, 30), font, 1, (0, 0, 255), 2)#Check in LRS\n",
    "      out_frame.append(mouth.T)\n",
    "    counter += 1\n",
    "\n",
    "\n",
    "  out_frame=np.asarray(out_frame).reshape(-1,100,50,3)\n",
    "  print(\"Original shape : \",out_frame.shape)\n",
    "  if out_frame.shape[0]<video_pad:\n",
    "    pad_array=np.zeros((video_pad-out_frame.shape[0],100,50,3))\n",
    "    out_frame=np.concatenate((out_frame, pad_array), axis=0)\n",
    "  #out_frame=(out_frame.astype('float32'))/255\n",
    "\n",
    "  return out_frame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sUFiR4Q1QKuL"
   },
   "source": [
    "## LRS Get files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 122
    },
    "id": "i_UFIfWiQKBF",
    "outputId": "2318a194-61e2-4449-f78b-f5f3297f4d81"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
      "\n",
      "Enter your authorization code:\n",
      "··········\n",
      "Mounted at /gdrive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/gdrive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 71
    },
    "id": "EgIbDyBGQZKS",
    "outputId": "fa667225-326c-4dad-ea36-e940b3b0b36a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cp: cannot open '/gdrive/My Drive/Hello Attention/Practice 3/Dataset/0af00UcTOSc/00001.gdoc' for reading: Operation not supported\n",
      "cp: cannot open '/gdrive/My Drive/Hello Attention/Practice 3/Dataset/0af00UcTOSc/00003.gdoc' for reading: Operation not supported\n"
     ]
    }
   ],
   "source": [
    "!cp -r '/gdrive/My Drive/Hello Attention/Practice 3/Dataset/0af00UcTOSc/' '/content/lrs1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "u_Ct4890QajZ"
   },
   "outputs": [],
   "source": [
    "out_dir='lrs1/'\n",
    "text_files = [out_dir + i for i in os.listdir(out_dir) if i.endswith(\".txt\")]\n",
    "video_files = [out_dir + i for i in os.listdir(out_dir) if i.endswith(\".mp4\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "id": "a6_F9zmVQdrn",
    "outputId": "0b3cc8bf-4b22-4e89-ede0-09aae53ef8cf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['lrs1/00001.mp4', 'lrs1/00002.mp4', 'lrs1/00003.mp4', 'lrs1/00004.mp4', 'lrs1/00005.mp4', 'lrs1/00006.mp4', 'lrs1/00007.mp4', 'lrs1/00008.mp4', 'lrs1/00009.mp4', 'lrs1/00010.mp4', 'lrs1/00011.mp4', 'lrs1/00012.mp4', 'lrs1/00013.mp4', 'lrs1/00014.mp4', 'lrs1/00015.mp4', 'lrs1/00016.mp4', 'lrs1/00017.mp4', 'lrs1/00018.mp4', 'lrs1/00019.mp4', 'lrs1/00020.mp4', 'lrs1/00021.mp4', 'lrs1/00022.mp4', 'lrs1/00023.mp4', 'lrs1/00024.mp4', 'lrs1/00025.mp4', 'lrs1/00027.mp4', 'lrs1/00028.mp4', 'lrs1/00029.mp4', 'lrs1/00030.mp4', 'lrs1/00031.mp4', 'lrs1/00032.mp4', 'lrs1/00033.mp4', 'lrs1/00034.mp4', 'lrs1/00035.mp4', 'lrs1/00036.mp4', 'lrs1/00037.mp4', 'lrs1/00038.mp4', 'lrs1/00039.mp4', 'lrs1/00040.mp4', 'lrs1/00041.mp4', 'lrs1/00042.mp4', 'lrs1/00043.mp4', 'lrs1/00044.mp4', 'lrs1/00045.mp4', 'lrs1/00046.mp4', 'lrs1/00047.mp4', 'lrs1/00048.mp4', 'lrs1/00049.mp4', 'lrs1/00050.mp4', 'lrs1/00051.mp4', 'lrs1/00052.mp4', 'lrs1/00053.mp4', 'lrs1/00054.mp4', 'lrs1/00055.mp4', 'lrs1/00056.mp4']\n"
     ]
    }
   ],
   "source": [
    "text_files=sorted(text_files)\n",
    "video_files=sorted(video_files)\n",
    "print(video_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 71
    },
    "id": "Tpzwaz61hwD_",
    "outputId": "291909ec-0903-4168-981f-19ea99b8bb21"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['lrs1/00001.mp4', 'lrs1/00002.mp4', 'lrs1/00003.mp4', 'lrs1/00004.mp4', 'lrs1/00005.mp4', 'lrs1/00006.mp4', 'lrs1/00007.mp4', 'lrs1/00008.mp4', 'lrs1/00009.mp4', 'lrs1/00010.mp4', 'lrs1/00011.mp4', 'lrs1/00012.mp4', 'lrs1/00013.mp4', 'lrs1/00014.mp4', 'lrs1/00015.mp4', 'lrs1/00016.mp4', 'lrs1/00017.mp4', 'lrs1/00018.mp4', 'lrs1/00019.mp4', 'lrs1/00020.mp4', 'lrs1/00021.mp4', 'lrs1/00022.mp4', 'lrs1/00023.mp4', 'lrs1/00024.mp4', 'lrs1/00025.mp4', 'lrs1/00027.mp4', 'lrs1/00028.mp4', 'lrs1/00029.mp4', 'lrs1/00030.mp4', 'lrs1/00031.mp4', 'lrs1/00032.mp4', 'lrs1/00033.mp4', 'lrs1/00034.mp4', 'lrs1/00035.mp4', 'lrs1/00036.mp4', 'lrs1/00037.mp4', 'lrs1/00038.mp4', 'lrs1/00039.mp4', 'lrs1/00040.mp4', 'lrs1/00041.mp4', 'lrs1/00042.mp4', 'lrs1/00043.mp4', 'lrs1/00044.mp4', 'lrs1/00045.mp4', 'lrs1/00046.mp4', 'lrs1/00047.mp4', 'lrs1/00048.mp4', 'lrs1/00049.mp4', 'lrs1/00050.mp4']\n",
      "['lrs1/00051.mp4', 'lrs1/00052.mp4', 'lrs1/00053.mp4', 'lrs1/00054.mp4', 'lrs1/00055.mp4', 'lrs1/00056.mp4']\n"
     ]
    }
   ],
   "source": [
    "#videos=[video_files[0],video_files[1],video_files[2],video_files[3],video_files[4]]\n",
    "#videos_train = video_files[:49]\n",
    "#videos_test = video_files[49:56]\n",
    "#print(videos_train)\n",
    "#print(videos_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "6sAa5otxQgyT",
    "outputId": "aa4bffe8-42a5-4ca9-adb7-5975623fa71f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "320\n"
     ]
    }
   ],
   "source": [
    "frame_numbers=[]\n",
    "for i in range(len(video_files)):\n",
    "  reader = skvideo.io.FFmpegReader(video_files[i])\n",
    "  (num_frames, h, w, c) = reader.getShape()\n",
    "  frame_numbers.append(num_frames)\n",
    "video_pad=max(frame_numbers)\n",
    "print(max(frame_numbers))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sAaDaTeaQvy6"
   },
   "source": [
    "## Preprocess Videos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1887
    },
    "id": "Cxg6WkryneTB",
    "outputId": "5004c4f2-e154-41da-bb54-f918adc75f12"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Video  0  : Original shape :  (137, 100, 50, 3)\n",
      "Appended Video shape :  (320, 100, 50, 3)\n",
      "Video  1  : Original shape :  (204, 100, 50, 3)\n",
      "Appended Video shape :  (320, 100, 50, 3)\n",
      "Video  2  : Original shape :  (157, 100, 50, 3)\n",
      "Appended Video shape :  (320, 100, 50, 3)\n",
      "Video  3  : Original shape :  (102, 100, 50, 3)\n",
      "Appended Video shape :  (320, 100, 50, 3)\n",
      "Video  4  : Original shape :  (151, 100, 50, 3)\n",
      "Appended Video shape :  (320, 100, 50, 3)\n",
      "Video  5  : Original shape :  (193, 100, 50, 3)\n",
      "Appended Video shape :  (320, 100, 50, 3)\n",
      "Video  6  : Original shape :  (243, 100, 50, 3)\n",
      "Appended Video shape :  (320, 100, 50, 3)\n",
      "Video  7  : Original shape :  (152, 100, 50, 3)\n",
      "Appended Video shape :  (320, 100, 50, 3)\n",
      "Video  8  : Original shape :  (168, 100, 50, 3)\n",
      "Appended Video shape :  (320, 100, 50, 3)\n",
      "Video  9  : Original shape :  (137, 100, 50, 3)\n",
      "Appended Video shape :  (320, 100, 50, 3)\n",
      "Video  10  : Original shape :  (100, 100, 50, 3)\n",
      "Appended Video shape :  (320, 100, 50, 3)\n",
      "Video  11  : Original shape :  (118, 100, 50, 3)\n",
      "Appended Video shape :  (320, 100, 50, 3)\n",
      "Video  12  : Original shape :  (168, 100, 50, 3)\n",
      "Appended Video shape :  (320, 100, 50, 3)\n",
      "Video  13  : Original shape :  (159, 100, 50, 3)\n",
      "Appended Video shape :  (320, 100, 50, 3)\n",
      "Video  14  : Original shape :  (205, 100, 50, 3)\n",
      "Appended Video shape :  (320, 100, 50, 3)\n",
      "Video  15  : Original shape :  (171, 100, 50, 3)\n",
      "Appended Video shape :  (320, 100, 50, 3)\n",
      "Video  16  : Original shape :  (253, 100, 50, 3)\n",
      "Appended Video shape :  (320, 100, 50, 3)\n",
      "Video  17  : Original shape :  (155, 100, 50, 3)\n",
      "Appended Video shape :  (320, 100, 50, 3)\n",
      "Video  18  : Original shape :  (172, 100, 50, 3)\n",
      "Appended Video shape :  (320, 100, 50, 3)\n",
      "Video  19  : Original shape :  (305, 100, 50, 3)\n",
      "Appended Video shape :  (320, 100, 50, 3)\n",
      "Video  20  : Original shape :  (320, 100, 50, 3)\n",
      "Appended Video shape :  (320, 100, 50, 3)\n",
      "Video  21  : Original shape :  (129, 100, 50, 3)\n",
      "Appended Video shape :  (320, 100, 50, 3)\n",
      "Video  22  : Original shape :  (106, 100, 50, 3)\n",
      "Appended Video shape :  (320, 100, 50, 3)\n",
      "Video  23  : Original shape :  (76, 100, 50, 3)\n",
      "Appended Video shape :  (320, 100, 50, 3)\n",
      "Video  24  : Original shape :  (94, 100, 50, 3)\n",
      "Appended Video shape :  (320, 100, 50, 3)\n",
      "Video  25  : Original shape :  (268, 100, 50, 3)\n",
      "Appended Video shape :  (320, 100, 50, 3)\n",
      "Video  26  : Original shape :  (263, 100, 50, 3)\n",
      "Appended Video shape :  (320, 100, 50, 3)\n",
      "Video  27  : Original shape :  (235, 100, 50, 3)\n",
      "Appended Video shape :  (320, 100, 50, 3)\n",
      "Video  28  : Original shape :  (142, 100, 50, 3)\n",
      "Appended Video shape :  (320, 100, 50, 3)\n",
      "Video  29  : Original shape :  (148, 100, 50, 3)\n",
      "Appended Video shape :  (320, 100, 50, 3)\n",
      "Video  30  : Original shape :  (232, 100, 50, 3)\n",
      "Appended Video shape :  (320, 100, 50, 3)\n",
      "Video  31  : Original shape :  (269, 100, 50, 3)\n",
      "Appended Video shape :  (320, 100, 50, 3)\n",
      "Video  32  : Original shape :  (114, 100, 50, 3)\n",
      "Appended Video shape :  (320, 100, 50, 3)\n",
      "Video  33  : Original shape :  (204, 100, 50, 3)\n",
      "Appended Video shape :  (320, 100, 50, 3)\n",
      "Video  34  : Original shape :  (107, 100, 50, 3)\n",
      "Appended Video shape :  (320, 100, 50, 3)\n",
      "Video  35  : Original shape :  (162, 100, 50, 3)\n",
      "Appended Video shape :  (320, 100, 50, 3)\n",
      "Video  36  : Original shape :  (156, 100, 50, 3)\n",
      "Appended Video shape :  (320, 100, 50, 3)\n",
      "Video  37  : Original shape :  (201, 100, 50, 3)\n",
      "Appended Video shape :  (320, 100, 50, 3)\n",
      "Video  38  : Original shape :  (203, 100, 50, 3)\n",
      "Appended Video shape :  (320, 100, 50, 3)\n",
      "Video  39  : Original shape :  (316, 100, 50, 3)\n",
      "Appended Video shape :  (320, 100, 50, 3)\n",
      "Video  40  : Original shape :  (141, 100, 50, 3)\n",
      "Appended Video shape :  (320, 100, 50, 3)\n",
      "Video  41  : Original shape :  (305, 100, 50, 3)\n",
      "Appended Video shape :  (320, 100, 50, 3)\n",
      "Video  42  : Original shape :  (304, 100, 50, 3)\n",
      "Appended Video shape :  (320, 100, 50, 3)\n",
      "Video  43  : Original shape :  (181, 100, 50, 3)\n",
      "Appended Video shape :  (320, 100, 50, 3)\n",
      "Video  44  : Original shape :  (286, 100, 50, 3)\n",
      "Appended Video shape :  (320, 100, 50, 3)\n",
      "Video  45  : Original shape :  (241, 100, 50, 3)\n",
      "Appended Video shape :  (320, 100, 50, 3)\n",
      "Video  46  : Original shape :  (237, 100, 50, 3)\n",
      "Appended Video shape :  (320, 100, 50, 3)\n",
      "Video  47  : Original shape :  (299, 100, 50, 3)\n",
      "Appended Video shape :  (320, 100, 50, 3)\n",
      "Video  48  : Original shape :  (236, 100, 50, 3)\n",
      "Appended Video shape :  (320, 100, 50, 3)\n",
      "Video  49  : Original shape :  (205, 100, 50, 3)\n",
      "Appended Video shape :  (320, 100, 50, 3)\n",
      "Video  50  : Original shape :  (236, 100, 50, 3)\n",
      "Appended Video shape :  (320, 100, 50, 3)\n",
      "Video  51  : Original shape :  (160, 100, 50, 3)\n",
      "Appended Video shape :  (320, 100, 50, 3)\n",
      "Video  52  : Original shape :  (180, 100, 50, 3)\n",
      "Appended Video shape :  (320, 100, 50, 3)\n",
      "Video  53  : Original shape :  (279, 100, 50, 3)\n",
      "Appended Video shape :  (320, 100, 50, 3)\n",
      "Video  54  : Original shape :  (214, 100, 50, 3)\n",
      "Appended Video shape :  (320, 100, 50, 3)\n"
     ]
    }
   ],
   "source": [
    "X_train=[]\n",
    "for i,v in enumerate(video_files):\n",
    "  #if i>2:\n",
    "    #break\n",
    "  print(\"Video \",i,\" : \",end=\"\")\n",
    "  out_frame=make_mouth_crops(v)\n",
    "  X_train.append(out_frame)\n",
    "  print(\"Appended Video shape : \",out_frame.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "P-BW0cpInien"
   },
   "outputs": [],
   "source": [
    "X_train = np.asarray(X_train)\n",
    "X_train = X_train.astype('float32')\n",
    "X_train /= 255"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "og1MyyIhsqVL"
   },
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6hhbfv1IspCG"
   },
   "outputs": [],
   "source": [
    "# Required parameters for mouth extraction.\n",
    "width_crop_max = 100\n",
    "height_crop_max = 50\n",
    "\n",
    "mouth_destination_path = 'mouth'\n",
    "if not os.path.exists(mouth_destination_path):\n",
    "    os.makedirs(mouth_destination_path)\n",
    "\n",
    "reader = skvideo.io.FFmpegReader(video_files[0]) #Change here ADD NAME INPUT VIDEO\n",
    "video_shape = reader.getShape()\n",
    "(num_frames, h, w, c) = video_shape\n",
    "print(num_frames, h, w, c)\n",
    "\n",
    "# The required parameters\n",
    "activation = []\n",
    "max_counter = 150\n",
    "total_num_frames = int(video_shape[0])\n",
    "num_frames = total_num_frames\n",
    "counter = 0\n",
    "font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "\n",
    "# Define the writer\n",
    "writer = skvideo.io.FFmpegWriter('mouth/output.mp4')\n",
    "\n",
    "\n",
    "for frame in reader.nextFrame():\n",
    "  #print('frame_shape:', frame.shape)\n",
    "  # Process the video and extract the frames up to a certain number and then stop processing.\n",
    "  #if counter > num_frames:\n",
    "    #break\n",
    "  # Detection of the frame\n",
    "  detections = detector(frame, 1)\n",
    "  # 20 mark for mouth\n",
    "  marks = np.zeros((2, 20))\n",
    "  # All unnormalized face features.\n",
    "  \n",
    "  Features_Abnormal = np.zeros((190, 1))\n",
    "  \n",
    "  # If the face is detected.\n",
    "  print(\"Detected\",len(detections))\n",
    "  \n",
    "  if len(detections) > 0:\n",
    "    # Shape of the face.\n",
    "    shape = predictor(frame, detections[0]) #single face considered \n",
    "    co = 0\n",
    "    # Specific for the mouth.\n",
    "    for ii in range(48, 68):\n",
    "      \"\"\"\n",
    "      This for loop is going over all mouth-related features.\n",
    "      X and Y coordinates are extracted and stored separately.\n",
    "      \"\"\"\n",
    "      X = shape.part(ii)\n",
    "      A = (X.x, X.y)\n",
    "      marks[0, co] = X.x\n",
    "      marks[1, co] = X.y\n",
    "      co += 1\n",
    "      \n",
    "    # Get the extreme points(top-left & bottom-right)\n",
    "    X_left, Y_left, X_right, Y_right = [int(np.amin(marks, axis=1)[0]), int(np.amin(marks, axis=1)[1]),\n",
    "                                        int(np.amax(marks, axis=1)[0]),\n",
    "                                        int(np.amax(marks, axis=1)[1])]\n",
    "    # Find the center of the mouth.\n",
    "    X_center = (X_left + X_right) / 2.0\n",
    "    Y_center = (Y_left + Y_right) / 2.0\n",
    "    print(\"Coordinates: \",X_left, Y_left, X_right, Y_right)\n",
    "    print(\"Center: \",X_center,Y_center)\n",
    "    # Make a boarder for cropping.\n",
    "    border = 15\n",
    "    X_left_new = X_left - border\n",
    "    Y_left_new = Y_left - border\n",
    "    X_right_new = X_right + border\n",
    "    Y_right_new = Y_right + border\n",
    "\n",
    "    # Width and height for cropping(before and after considering the border).\n",
    "    width_new = X_right_new - X_left_new\n",
    "    height_new = Y_right_new - Y_left_new\n",
    "    width_current = X_right - X_left\n",
    "    height_current = Y_right - Y_left\n",
    "\n",
    "\n",
    "    # Determine the cropping rectangle dimensions(the main purpose is to have a fixed area).\n",
    "    if width_crop_max == 0 and height_crop_max == 0:\n",
    "      width_crop_max = width_new\n",
    "      height_crop_max = height_new\n",
    "    else:\n",
    "      width_crop_max += 1.5 * np.maximum(width_current - width_crop_max, 0)\n",
    "      height_crop_max += 1.5 * np.maximum(height_current - height_crop_max, 0)\n",
    "      \n",
    "    # # # Uncomment if the lip area is desired to be rectangular # # # #\n",
    "    #########################################################\n",
    "    # Find the cropping points(top-left and bottom-right).\n",
    "    X_left_crop = int(X_center - width_crop_max / 2.0)\n",
    "    X_right_crop = int(X_center + width_crop_max / 2.0)\n",
    "    Y_left_crop = int(Y_center - height_crop_max / 2.0)\n",
    "    Y_right_crop = int(Y_center + height_crop_max / 2.0)\n",
    "    #########################################################\n",
    "\n",
    "    # # # # # Uncomment if the lip area is desired to be rectangular # # # #\n",
    "    # #######################################\n",
    "    # # Use this part if the cropped area should look like a square.\n",
    "    #crop_length_max = max(width_crop_max, height_crop_max) / 2\n",
    "    #\n",
    "    # # Find the cropping points(top-left and bottom-right).\n",
    "\n",
    "    #X_left_crop = int(X_center - crop_length_max)\n",
    "    #X_right_crop = int(X_center + crop_length_max)\n",
    "    #Y_left_crop = int(Y_center - crop_length_max)\n",
    "    #Y_right_crop = int(Y_center + crop_length_max)\n",
    "    #########################################\n",
    "\n",
    "    if X_left_crop >= 0 and Y_left_crop >= 0 and X_right_crop < w and Y_right_crop < h:\n",
    "      mouth = frame[Y_left_crop:Y_right_crop, X_left_crop:X_right_crop, :]\n",
    "      # Save the mouth area.\n",
    "      #mouth_gray = cv2.cvtColor(mouth, cv2.COLOR_RGB2GRAY)\n",
    "      cv2.imwrite(mouth_destination_path + '/' + 'frame' + '_' + str(counter) + '.png', mouth)\n",
    "      \n",
    "      activation.append(1)\n",
    "    else:\n",
    "      cv2.putText(frame, 'The full mouth is not detectable. ', (30, 30), font, 1, (0, 255, 255), 2)\n",
    "      print(\"No activation\")\n",
    "      activation.append(0)\n",
    "\n",
    "  else:\n",
    "    cv2.putText(frame, 'No Face', (30, 30), font, 1, (0, 0, 255), 2)\n",
    "    print(\"No Face for frame \",counter)\n",
    "    activation.append(0)\n",
    "    #mouth = frame[Y_center-25: Y_center+25, X_center-50: X_center+50,:]\n",
    "    cv2.imwrite(mouth_destination_path + '/' + 'frame' + '_' + str(counter) + '.png', mouth)\n",
    "\n",
    "  if activation[counter] == 1:\n",
    "    # Demonstration of face.\n",
    "    cv2.rectangle(frame, (X_left_crop, Y_left_crop), (X_right_crop, Y_right_crop), (0, 255, 0), 2)\n",
    "    # cv2.imshow('frame', frame)\n",
    "    print('frame number %d of %d' % (counter, num_frames))\n",
    "\n",
    "    # write the output frame to file\n",
    "  print(\"writing frame %d with activation %d\" % (counter + 1, activation[counter]))\n",
    "  writer.writeFrame(frame) \n",
    "  \n",
    "  counter += 1\n",
    "\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4N1zWuCeopB7"
   },
   "source": [
    "#Text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "y7Hkb3FAyjHQ"
   },
   "source": [
    "## Grid Text Get Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TGHipIQMHu7g"
   },
   "outputs": [],
   "source": [
    "!wget http://spandh.dcs.shef.ac.uk/gridcorpus/s1/align/s1.tar\n",
    "!tar -xvf s1.tar && rm -r s1.tar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "evr2j2R_Hvz5"
   },
   "outputs": [],
   "source": [
    "#files=['swwp2s.align','priazn.align']\n",
    "def prep_text(files):\n",
    "  sent=[]\n",
    "  for file in files:\n",
    "    f = open(file, \"r\")\n",
    "    dummy=[line.split()[-1] for line in f] #-1 coz that's the word we want, 0 and 1 have timestamps\n",
    "    dummy[0]='<start>'\n",
    "    dummy[-1]='<end>'\n",
    "    sent.append(dummy)\n",
    "  return sent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Qpk7DW5yHy6x"
   },
   "outputs": [],
   "source": [
    "text_dir='align/'\n",
    "files = [text_dir + i for i in os.listdir(text_dir)]\n",
    "files=sorted(files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pI1YUhdoISTr"
   },
   "outputs": [],
   "source": [
    "sent = prep_text(files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AlVqls-RIZKY"
   },
   "outputs": [],
   "source": [
    "b=np.array(sent)\n",
    "sent=list(b[index_list])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 289
    },
    "id": "yswdwkpSiC6K",
    "outputId": "f06bdccc-4a85-4bbd-d2fa-2cb87ebb942a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['<start>', 'bin', 'blue', 'at', 'f', 'two', 'now', '<end>'],\n",
       " ['<start>', 'bin', 'green', 'at', 'a', 'six', 'now', '<end>'],\n",
       " ['<start>', 'bin', 'red', 'at', 'f', 'eight', 'now', '<end>'],\n",
       " ['<start>', 'bin', 'white', 'at', 'a', 'one', 'soon', '<end>'],\n",
       " ['<start>', 'lay', 'blue', 'at', 'd', 'six', 'now', '<end>'],\n",
       " ['<start>', 'lay', 'green', 'at', 'f', 'four', 'now', '<end>'],\n",
       " ['<start>', 'lay', 'red', 'at', 'e', 'two', 'now', '<end>'],\n",
       " ['<start>', 'lay', 'white', 'at', 'e', 'eight', 'now', '<end>'],\n",
       " ['<start>', 'place', 'blue', 'at', 'c', 'one', 'soon', '<end>'],\n",
       " ['<start>', 'place', 'green', 'at', 'd', 'eight', 'now', '<end>'],\n",
       " ['<start>', 'place', 'red', 'at', 'c', 'six', 'now', '<end>'],\n",
       " ['<start>', 'place', 'white', 'at', 'd', 'two', 'now', '<end>'],\n",
       " ['<start>', 'set', 'blue', 'at', 'a', 'four', 'now', '<end>'],\n",
       " ['<start>', 'set', 'green', 'at', 'c', 'two', 'now', '<end>'],\n",
       " ['<start>', 'set', 'red', 'at', 'b', 'one', 'soon', '<end>'],\n",
       " ['<start>', 'set', 'white', 'at', 'b', 'six', 'now', '<end>']]"
      ]
     },
     "execution_count": 27,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "N3H10FXnRQsF"
   },
   "source": [
    "## LRS Text Preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6RrAHD-3RU0X"
   },
   "outputs": [],
   "source": [
    "#texts=[text_files[0],text_files[1],text_files[2],text_files[3],text_files[4], text_files[7]] #, text_files[7]\n",
    "def prep_text(files):\n",
    "  sent=[]\n",
    "  for file in files:\n",
    "    dummy=[]\n",
    "    f = open(file, \"r\")\n",
    "    for line in f:\n",
    "      dummy.extend(line.split())\n",
    "\n",
    "    index_conf=dummy.index('Conf:')\n",
    "    dummy=dummy[:index_conf+1]\n",
    "    dummy[0]='<start>'\n",
    "    dummy[-1]='<end>'\n",
    "    print(dummy)\n",
    "    sent.append(dummy)\n",
    "  return sent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 972
    },
    "id": "nwV1I5eMRXxp",
    "outputId": "ec72d2aa-6bd7-42ee-f6e4-3b6e0e004c6f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['<start>', 'TO', 'SHOW', 'IT', 'TO', 'YOU', 'NOT', 'BECAUSE', 'I', 'WANT', 'TO', 'GIVE', 'YOU', 'THE', 'KIND', 'OF', 'STARBUCKS', 'TOUR', 'OF', 'HISTORIC', 'ENGLAND', 'BUT', '<end>']\n",
      "['<start>', 'BEFORE', 'THE', 'SPREAD', 'OF', 'COFFEE', 'AND', 'TEA', 'THROUGH', 'BRITISH', 'CULTURE', 'WHAT', 'PEOPLE', 'DRANK', 'BOTH', 'ELITE', 'AND', 'MASS', 'FOLKS', 'DRANK', '<end>']\n",
      "['<start>', 'DRINKING', 'ALL', 'DAY', 'AND', 'THEN', 'YOU', 'SWITCHED', 'FROM', 'A', 'DEPRESSANT', 'TO', 'A', 'STIMULANT', 'IN', 'YOUR', '<end>']\n",
      "['<start>', 'WHERE', 'PEOPLE', 'WOULD', 'GET', 'TOGETHER', 'FROM', 'DIFFERENT', 'BACKGROUNDS', 'DIFFERENT', 'FIELDS', 'OF', 'EXPERTISE', '<end>']\n",
      "['<start>', 'IT', 'WAS', 'A', 'SPACE', 'AS', 'MATT', 'RIDLEY', 'TALKED', 'ABOUT', 'WHERE', 'IDEAS', 'COULD', 'HAVE', 'SEX', 'THIS', 'WAS', 'THEIR', 'CONJUGAL', 'BED', 'IN', 'A', '<end>']\n",
      "['<start>', 'SPENDING', 'A', 'LOT', 'OF', 'TIME', 'THINKING', 'ABOUT', 'COFFEEHOUSES', 'FOR', 'THE', 'LAST', 'FIVE', 'YEARS', 'BECAUSE', \"I'VE\", 'BEEN', 'KIND', 'OF', 'ON', 'THIS', 'QUEST', 'TO', 'INVESTIGATE', 'THIS', '<end>']\n",
      "['<start>', 'OF', 'CREATIVITY', 'AND', 'WHAT', \"I'VE\", 'DONE', 'IS', \"I'VE\", 'LOOKED', 'AT', 'BOTH', 'ENVIRONMENTS', 'LIKE', 'THE', 'COFFEEHOUSE', \"I'VE\", 'LOOKED', 'AT', 'MEDIA', 'ENVIRONMENTS', 'LIKE', 'THE', 'WORLD', 'WIDE', 'WEB', 'THAT', 'HAVE', 'BEEN', 'EXTRAORDINARILY', 'INNOVATIVE', '<end>']\n",
      "['<start>', 'IS', 'SHARED', 'PATTERNS', 'KIND', 'OF', 'SIGNATURE', 'BEHAVIOR', 'THAT', 'SHOWS', 'UP', 'AGAIN', 'AND', 'AGAIN', 'IN', 'ALL', 'OF', 'THESE', '<end>']\n",
      "['<start>', 'RECURRING', 'PATTERNS', 'THAT', 'WE', 'CAN', 'LEARN', 'FROM', 'THAT', 'WE', 'CAN', 'TAKE', 'AND', 'KIND', 'OF', 'APPLY', 'TO', 'OUR', 'OWN', 'LIVES', 'OR', 'OUR', 'OWN', 'ORGANIZATIONS', 'OR', 'OUR', 'OWN', 'ENVIRONMENTS', '<end>']\n",
      "['<start>', 'METAPHORS', 'AND', 'LANGUAGE', 'STEERS', 'US', 'TOWARDS', 'CERTAIN', 'CONCEPTS', 'OF', 'IDEA', 'CREATION', 'WE', '<end>']\n",
      "['<start>', 'WONDERFUL', 'ILLUMINATING', 'MOMENT', 'BUT', 'IN', 'FACT', 'WHAT', '<end>']\n",
      "['<start>', 'NETWORK', 'OF', 'NEURONS', 'FIRING', 'IN', 'SYNC', 'WITH', 'EACH', 'OTHER', 'INSIDE', 'YOUR', 'BRAIN', \"IT'S\", 'A', 'NEW', 'CONFIGURATION', '<end>']\n",
      "['<start>', 'BEFORE', 'AND', 'THE', 'QUESTION', 'IS', 'HOW', 'DO', 'YOU', 'GET', 'YOUR', 'BRAIN', 'INTO', 'ENVIRONMENTS', 'WHERE', 'THESE', 'NEW', 'NETWORKS', 'ARE', 'GOING', 'TO', 'BE', 'MORE', 'LIKELY', 'TO', 'FORM', '<end>']\n",
      "['<start>', 'THAT', 'IN', 'FACT', 'THE', 'KIND', 'OF', 'NETWORK', 'PATTERNS', 'OF', 'THE', 'OUTSIDE', 'WORLD', 'MIMIC', 'LOT', 'OF', 'THE', 'NETWORK', 'PATTERNS', 'OF', 'THE', 'INTERNAL', 'WORLD', 'OF', 'THE', 'HUMAN', '<end>']\n",
      "['<start>', 'TO', 'TACKLE', 'THIS', 'REALLY', 'PRESSING', 'PROBLEM', 'OF', 'YOU', 'KNOW', 'THE', 'TERRIBLE', 'PROBLEMS', 'WE', 'HAVE', 'WITH', 'INFANT', 'MORTALITY', 'RATES', 'IN', 'THE', 'DEVELOPING', 'WORLD', '<end>']\n",
      "['<start>', \"THAT'S\", 'VERY', 'FRUSTRATING', 'ABOUT', 'THIS', 'IS', 'THAT', 'WE', 'KNOW', 'BY', 'GETTING', 'MODERN', 'NEONATAL', 'INCUBATORS', 'INTO', 'ANY', '<end>']\n",
      "['<start>', 'PREMATURE', 'BABIES', 'WARM', 'BASICALLY', \"IT'S\", 'VERY', 'SIMPLE', 'WE', 'CAN', 'HALVE', 'INFANT', 'MORTALITY', 'RATES', 'IN', 'THOSE', 'ENVIRONMENTS', 'SO', 'THE', 'TECHNOLOGY', 'IS', 'THERE', 'THESE', 'ARE', 'STANDARD', 'IN', 'ALL', 'THE', 'INDUSTRIALIZED', 'WORLDS', '<end>']\n",
      "['<start>', 'GREAT', 'FOR', 'YEAR', 'OR', 'TWO', 'YEARS', 'AND', 'THEN', 'SOMETHING', 'WILL', 'GO', 'WRONG', 'AND', 'IT', 'WILL', 'BREAK', 'AND', 'IT', 'WILL', 'REMAIN', 'BROKEN', 'FOREVER', '<end>']\n",
      "['<start>', 'A', 'WHOLE', 'SYSTEM', 'OF', 'SPARE', 'PARTS', 'AND', 'YOU', \"DON'T\", 'HAVE', 'THE', 'ON', 'THE', 'GROUND', 'EXPERTISE', 'TO', 'FIX', 'THIS', '40000', 'PIECE', 'OF', 'EQUIPMENT', 'AND', '<end>']\n",
      "['<start>', 'AND', 'SEE', 'WHAT', 'ARE', 'THE', 'ABUNDANT', 'RESOURCES', 'IN', 'THESE', 'DEVELOPING', 'WORLD', 'CONTEXTS', 'AND', 'WHAT', 'THEY', 'NOTICED', 'WAS', 'THEY', \"DON'T\", 'HAVE', 'A', 'LOT', 'OF', 'DVRS', 'THEY', \"DON'T\", 'HAVE', 'A', 'LOT', 'OF', 'MICROWAVES', 'BUT', 'THEY', 'SEEM', 'TO', 'DO', 'A', 'PRETTY', 'GOOD', 'JOB', 'OF', 'KEEPING', 'THEIR', 'CARS', 'ON', 'THE', 'ROAD', '<end>']\n",
      "['<start>', 'FORERUNNER', 'ON', 'THE', 'STREET', 'IN', 'ALL', 'THESE', 'PLACES', 'THEY', 'SEEM', 'TO', 'HAVE', 'THE', 'EXPERTISE', 'TO', 'KEEP', 'CARS', 'WORKING', 'SO', 'THEY', 'STARTED', 'TO', 'THINK', 'COULD', 'WE', 'BUILD', 'A', 'NEONATAL', 'INCUBATOR', \"THAT'S\", 'BUILT', 'ENTIRELY', 'OUT', 'OF', 'AUTOMOBILE', '<end>']\n",
      "['<start>', 'THINK', 'OUR', 'BREAKTHROUGH', 'IDEAS', 'YOU', 'KNOW', 'ARE', 'LIKE', 'THAT', '40000', 'BRAND', 'NEW', 'INCUBATOR', 'STATE', 'OF', 'THE', 'ART', '<end>']\n",
      "['<start>', 'THEM', 'TOGETHER', 'INTO', 'NEW', 'FORMS', 'AND', 'WE', 'CREATE', 'SOMETHING', 'NEW', \"THAT'S\", 'REALLY', 'WHERE', 'INNOVATION', '<end>']\n",
      "['<start>', 'THE', 'SPACES', 'THAT', 'HAVE', 'HISTORICALLY', 'LED', 'TO', 'INNOVATION', 'TEND', 'TO', 'LOOK', '<end>']\n",
      "['<start>', 'THAT', 'ARE', 'MORE', 'INNOVATIVE', 'WE', 'HAVE', 'TO', 'BUILD', 'SPACES', 'THAT', 'STRANGELY', 'ENOUGH', 'LOOK', 'A', 'LITTLE', 'BIT', 'MORE', 'LIKE', '<end>']\n",
      "['<start>', 'TO', 'A', 'BUNCH', 'OF', 'SCIENCE', 'LABS', 'AROUND', 'THE', 'WORLD', 'AND', 'VIDEOTAPED', 'EVERYONE', 'AS', 'THEY', 'WERE', 'DOING', 'EVERY', 'LITTLE', 'BIT', 'OF', 'THEIR', 'JOB', 'SO', 'WHEN', 'THEY', 'WERE', 'SITTING', 'IN', 'FRONT', 'OF', 'THE', 'MICROSCOPE', 'WHEN', 'THEY', 'WERE', 'TALKING', 'TO', 'THEIR', 'COLLEAGUE', 'AT', 'THE', 'WATER', 'COOLER', 'AND', 'ALL', 'THESE', 'THINGS', 'AND', '<end>']\n",
      "['<start>', \"THEY'VE\", 'GOT', 'THE', 'IDEA', 'WHAT', 'HAPPENED', 'ACTUALLY', 'WHEN', 'DUNBAR', 'KIND', 'OF', 'LOOKED', 'AT', 'THE', 'TAPE', 'IS', 'THAT', 'IN', 'FACT', 'ALMOST', 'ALL', 'OF', 'THE', 'IMPORTANT', 'BREAKTHROUGH', 'IDEAS', 'DID', 'NOT', 'HAPPEN', 'ALONE', 'IN', 'THE', 'LAB', 'IN', 'FRONT', 'OF', 'THE', '<end>']\n",
      "['<start>', 'OF', 'DIFFERENT', 'IDEAS', 'THAT', 'ARE', 'TOGETHER', 'DIFFERENT', 'BACKGROUNDS', 'DIFFERENT', 'INTERESTS', 'JOSTLING', 'WITH', 'EACH', 'OTHER', 'BOUNCING', 'OFF', 'EACH', 'OTHER', 'THAT', 'ENVIRONMENT', 'IS', 'IN', 'FACT', 'THE', 'ENVIRONMENT', 'THAT', 'LEADS', 'TO', '<end>']\n",
      "['<start>', 'THAT', \"THERE'S\", 'AN', 'INTERESTING', 'PROBLEM', 'BUT', 'THEY', \"DON'T\", 'QUITE', 'HAVE', 'THE', 'TOOLS', 'YET', 'TO', 'DISCOVER', 'THEM', 'THEY', 'SPEND', 'ALL', 'THIS', 'TIME', '<end>']\n",
      "['<start>', 'ACTUALLY', 'ON', 'POPULATION', 'AND', 'ALL', 'OF', 'A', 'SUDDEN', 'THE', 'BASIC', 'ALGORITHM', 'OF', 'NATURAL', 'SELECTION', 'KIND', 'OF', 'POPS', 'INTO', 'HIS', 'HEAD', 'AND', 'HE', '<end>']\n",
      "['<start>', 'IS', 'THAT', 'DARWIN', 'IN', 'A', 'SENSE', 'HAD', 'THE', 'IDEA', 'HE', 'HAD', 'THE', 'CONCEPT', 'BUT', 'WAS', 'UNABLE', 'OF', 'FULLY', 'THINKING', 'IT', 'YET', 'AND', 'THAT', 'IS', 'ACTUALLY', 'HOW', 'GREAT', 'IDEAS', 'OFTEN', '<end>']\n",
      "['<start>', 'AN', 'EXCELLENT', 'IDEA', 'FOR', 'OUR', 'ORGANIZATION', 'IT', 'WILL', 'BE', 'USEFUL', 'IN', '2020', 'COULD', 'YOU', 'JUST', 'GIVE', 'ME', 'SOME', 'TIME', 'TO', 'DO', 'THAT', 'NOW', 'COUPLE', 'OF', 'COMPANIES', 'LIKE', 'GOOGLE', 'THEY', 'HAVE', 'INNOVATION', 'TIME', 'OFF', '20', 'PERCENT', 'TIME', 'WHERE', 'IN', 'A', '<end>']\n",
      "['<start>', 'HUNCH', 'CULTIVATING', 'MECHANISMS', 'IN', 'AN', 'ORGANIZATION', 'BUT', \"THAT'S\", 'A', '<end>']\n",
      "['<start>', 'OF', 'AN', 'IDEA', 'SOMEBODY', 'ELSE', 'HAS', 'THE', 'OTHER', 'HALF', 'AND', 'IF', \"YOU'RE\", 'IN', 'THE', 'RIGHT', 'ENVIRONMENT', 'THEY', 'TURN', 'INTO', 'SOMETHING', 'LARGER', 'THAN', 'THE', 'SUM', 'OF', 'THEIR', 'PARTS', 'SO', 'IN', 'A', 'SENSE', 'WE', 'OFTEN', 'TALK', '<end>']\n",
      "['<start>', 'OF', 'PROTECTING', 'INTELLECTUAL', 'PROPERTY', 'YOU', 'KNOW', 'BUILDING', 'BARRICADES', '<end>']\n",
      "['<start>', 'IDEAS', 'AND', 'THE', 'CULTURE', 'WILL', 'BE', 'MORE', 'INNOVATIVE', 'BUT', 'I', 'THINK', \"THERE'S\", 'A', 'CASE', 'TO', 'BE', 'MADE', 'THAT', 'WE', 'SHOULD', 'SPEND', 'AT', 'LEAST', 'AS', 'MUCH', 'TIME', 'IF', '<end>']\n",
      "['<start>', 'A', 'LOT', 'OF', 'THESE', 'VALUES', 'AND', \"IT'S\", 'JUST', 'WONDERFUL', 'KIND', 'OF', 'TALE', 'OF', 'INNOVATION', 'AND', 'HOW', 'IT', 'HAPPENS', 'IN', 'UNLIKELY', '<end>']\n",
      "['<start>', 'MORNING', 'AND', 'THE', 'NEWS', 'HAS', 'JUST', 'BROKEN', 'ABOUT', 'THIS', 'SATELLITE', \"THAT'S\", 'NOW', 'ORBITING', 'THE', 'PLANET', 'AND', 'OF', 'COURSE', 'THIS', 'IS', 'NERD', 'HEAVEN', 'RIGHT', 'THERE', 'ARE', 'ALL', '<end>']\n",
      "['<start>', 'GEEKS', 'WHO', 'ARE', 'THERE', 'THINKING', 'OH', 'MY', 'GOSH', 'THIS', 'IS', 'INCREDIBLE', 'I', \"CAN'T\", 'BELIEVE', 'THIS', 'HAS', 'HAPPENED', 'AND', 'TWO', 'OF', 'THEM', 'TWO', '20', 'SOMETHING', 'RESEARCHERS', 'AT', 'THE', 'APL', 'ARE', '<end>']\n",
      "['<start>', 'AT', 'THE', 'CAFETERIA', 'TABLE', 'HAVING', 'AN', 'INFORMAL', 'CONVERSATION', 'WITH', 'A', 'BUNCH', 'OF', 'THEIR', 'COLLEAGUES', 'AND', 'THESE', 'TWO', 'GUYS', 'ARE', 'NAMED', 'GUIER', 'AND', 'WEIFFENBACH', 'AND', 'THEY', 'START', 'TALKING', 'AND', 'ONE', 'OF', 'THEM', 'SAYS', 'HEY', 'HAS', 'ANYBODY', 'TRIED', 'TO', 'LISTEN', 'FOR', 'THIS', 'THING', \"THERE'S\", 'THIS', '<end>']\n",
      "['<start>', 'OF', 'THEIR', 'COLLEAGUES', 'AND', \"EVERYBODY'S\", 'LIKE', 'NO', 'I', \"HADN'T\", 'THOUGHT', 'OF', 'DOING', 'THAT', \"THAT'S\", 'AN', 'INTERESTING', 'IDEA', 'AND', 'IT', 'TURNS', '<end>']\n",
      "['<start>', 'IS', 'KIND', 'OF', 'AN', 'EXPERT', 'IN', 'MICROWAVE', 'RECEPTION', 'AND', \"HE'S\", 'GOT', 'A', 'LITTLE', 'ANTENNAE', 'SET', 'UP', 'WITH', 'AN', 'AMPLIFIER', 'IN', 'HIS', 'OFFICE', 'AND', 'SO', 'GUIER', 'AND', 'WEIFFENBACH', 'GO', 'BACK', 'TO', \"WEIFFENBACH'S\", 'OFFICE', 'AND', 'THEY', 'START', 'KIND', 'OF', 'NOODLING', 'AROUND', 'HACKING', 'AS', 'WE', 'MIGHT', 'CALL', 'IT', 'NOW', '<end>']\n",
      "['<start>', 'COUPLE', 'OF', 'HOURS', 'THEY', 'ACTUALLY', 'START', 'PICKING', 'UP', 'THE', 'SIGNAL', 'BECAUSE', 'THE', 'SOVIETS', 'MADE', 'SPUTNIK', 'VERY', 'EASY', 'TO', 'TRACK', 'IT', 'WAS', 'RIGHT', 'AT', '20', 'MHZ', 'SO', 'YOU', 'COULD', 'PICK', 'IT', 'UP', 'REALLY', 'EASILY', 'BECAUSE', 'THEY', 'WERE', 'AFRAID', 'THAT', 'PEOPLE', 'WOULD', 'THINK', 'IT', 'WAS', 'HOAX', 'BASICALLY', 'SO', 'THEY', 'MADE', 'IT', 'REALLY', 'EASY', 'TO', '<end>']\n",
      "['<start>', 'IS', 'KIND', 'OF', 'HISTORIC', 'WE', 'MAY', 'BE', 'THE', 'FIRST', 'PEOPLE', 'IN', 'THE', 'UNITED', 'STATES', 'TO', 'BE', 'LISTENING', 'TO', 'THIS', 'WE', 'SHOULD', 'RECORD', 'IT', 'AND', 'SO', 'THEY', 'BRING', 'IN', 'THIS', 'BIG', 'CLUNKY', 'ANALOG', 'TAPE', 'RECORDER', 'AND', '<end>']\n",
      "['<start>', 'THESE', 'LITTLE', 'BLEEP', 'BLEEPS', 'AND', 'THEY', 'START', 'WRITING', 'THE', 'KIND', 'OF', 'DATE', 'STAMP', 'TIME', 'STAMPS', 'FOR', 'EACH', 'LITTLE', 'BLEEP', 'THAT', 'THEY', 'RECORD', 'AND', 'THEY', 'THEY', 'START', 'THINKING', 'WELL', 'GOSH', 'YOU', 'KNOW', \"WE'RE\", 'NOTICING', 'SMALL', '<end>']\n",
      "['<start>', 'VARIATIONS', 'HERE', 'WE', 'COULD', 'PROBABLY', 'CALCULATE', 'THE', 'SPEED', 'THAT', 'THE', 'SATELLITE', 'IS', 'TRAVELING', 'IF', 'WE', 'DO', 'LITTLE', 'BASIC', 'MATH', 'HERE', 'USING', 'THE', 'DOPPLER', '<end>']\n",
      "['<start>', 'WE', 'COULD', 'ACTUALLY', 'TAKE', 'A', 'LOOK', 'AT', 'THE', 'SLOPE', 'OF', 'THE', 'DOPPLER', 'EFFECT', 'TO', 'FIGURE', 'OUT', 'THE', 'POINTS', 'AT', 'WHICH', 'THE', 'SATELLITE', 'IS', 'CLOSEST', 'TO', 'OUR', 'ANTENNAE', 'AND', 'THE', 'POINTS', 'AT', 'WHICH', \"IT'S\", 'FARTHEST', 'AWAY', \"THAT'S\", 'PRETTY', 'COOL', '<end>']\n",
      "['<start>', 'THEY', 'GET', 'PERMISSION', 'THIS', 'IS', 'ALL', 'A', 'LITTLE', 'SIDE', 'PROJECT', 'THAT', \"HADN'T\", 'BEEN', 'OFFICIALLY', 'PART', 'OF', 'THEIR', 'JOB', 'DESCRIPTION', 'THEY', 'GET', 'PERMISSION', 'TO', 'USE', 'THE', 'NEW', 'YOU', 'KNOW', 'UNIVAC', 'COMPUTER', 'THAT', 'TAKES', 'UP', 'AN', 'ENTIRE', 'ROOM', 'THAT', \"THEY'D\", 'JUST', 'GOTTEN', 'AT', 'THE', 'APL', 'THEY', 'RUN', 'SOME', 'MORE', 'OF', 'THE', 'NUMBERS', '<end>']\n",
      "['<start>', 'ABOUT', 'THREE', 'OR', 'FOUR', 'WEEKS', 'TURNS', 'OUT', 'THEY', 'HAVE', 'MAPPED', 'THE', 'EXACT', 'TRAJECTORY', 'OF', 'THIS', 'SATELLITE', 'AROUND', 'THE', 'EARTH', 'JUST', 'FROM', 'LISTENING', 'TO', 'THIS', 'ONE', 'LITTLE', 'SIGNAL', 'GOING', 'OFF', 'ON', 'THIS', 'LITTLE', 'SIDE', '<end>']\n",
      "['<start>', 'ON', \"YOU'VE\", 'FIGURED', 'OUT', 'AN', 'UNKNOWN', 'LOCATION', 'OF', 'SATELLITE', 'ORBITING', 'THE', 'PLANET', 'FROM', 'A', 'KNOWN', 'LOCATION', 'ON', 'THE', 'GROUND', '<end>']\n",
      "['<start>', 'THE', 'OTHER', 'WAY', 'COULD', 'YOU', 'FIGURE', 'OUT', 'AN', 'UNKNOWN', 'LOCATION', 'ON', 'THE', 'GROUND', 'IF', 'YOU', 'KNEW', 'THE', 'LOCATION', 'OF', 'THE', 'SATELLITE', 'AND', 'THEY', 'THOUGHT', 'ABOUT', 'IT', 'AND', 'THEY', 'SAID', 'WELL', 'I', 'GUESS', 'MAYBE', 'YOU', 'COULD', '<end>']\n",
      "['<start>', 'SAID', 'OH', \"THAT'S\", 'GREAT', 'BECAUSE', 'SEE', 'I', 'HAVE', 'THESE', 'NEW', 'NUCLEAR', 'SUBMARINES', 'THAT', \"I'M\", 'BUILDING', 'AND', '<end>']\n",
      "['<start>', 'A', 'BUNCH', 'OF', 'SATELLITES', 'AND', 'USE', 'IT', 'TO', 'TRACK', 'OUR', 'SUBMARINES', 'AND', 'FIGURE', 'OUT', 'THEIR', 'LOCATION', 'IN', 'THE', 'MIDDLE', 'OF', 'THE', 'OCEAN', 'COULD', 'YOU', 'WORK', 'ON', 'THAT', '<end>']\n",
      "['<start>', 'IF', 'NOT', 'MORE', 'HAS', 'USED', 'SAID', 'DEVICE', 'AND', 'SAID', 'SATELLITE', 'SYSTEM', 'TO', 'LOCATE', 'A', 'NEARBY', 'COFFEEHOUSE', 'SOMEWHERE', 'IN', 'THE', 'LAST', '{LG}', 'IN', 'THE', 'LAST', 'DAY', 'OR', 'LAST', 'WEEK', '<end>']\n",
      "['<start>', 'EVEN', 'DREAMED', 'OF', 'MEAN', 'HERE', 'YOU', 'HAVE', 'THESE', 'GUYS', 'WHO', 'BASICALLY', 'THOUGHT', 'THEY', 'WERE', 'JUST', 'FOLLOWING', 'THIS', 'HUNCH', 'THIS', 'LITTLE', 'PASSION', 'THAT', 'HAD', 'DEVELOPED', 'THEN', 'THEY', 'THOUGHT', 'THEY', 'WERE', 'FIGHTING', 'THE', 'COLD', 'WAR', '<end>']\n"
     ]
    }
   ],
   "source": [
    "sent=prep_text(text_files)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Vb0H_3oxyon_"
   },
   "source": [
    "## Prep Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "vav-UhbOsxcU",
    "outputId": "3f59bc44-aef8-4448-948c-4577583e0a9d"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.text import Tokenizer \n",
    "from keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LTamCKp0sy_N"
   },
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(oov_token=\"<unk>\", filters='!\"#$%&()*+.,-/:;=?@[\\]^_`{|}~ ')\n",
    "tokenizer.fit_on_texts(sent)\n",
    "tokenizer.word_index['<pad>'] = 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MVUPxiipuO4t"
   },
   "outputs": [],
   "source": [
    "sseq = tokenizer.texts_to_sequences(sent)\n",
    "#sseq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "m-3qo1h5vzj1"
   },
   "outputs": [],
   "source": [
    "decoder_input_data=pad_sequences(sseq, padding='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NZ9tL_WDxLxd"
   },
   "outputs": [],
   "source": [
    "#decoder_input_data=decoder_input_data.astype('float32')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LFKwLwaFmikV"
   },
   "source": [
    "#Trash"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vl8y1s-wRI66"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pGDRLHx5PN52"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "out_dir='output/'\n",
    "mouths = [out_dir + i+'/' for i in os.listdir(out_dir)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "eo6kJNt4Uh9P",
    "outputId": "e1f2f66a-ed24-47d7-8d13-2c7169426cf9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['output/mouth1/', 'output/mouth0/']"
      ]
     },
     "execution_count": 3,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mouths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TfPZgylmQgA6"
   },
   "outputs": [],
   "source": [
    "def prep_data(images):\n",
    "    count = len(images)\n",
    "    data = np.ndarray((count,3,100,50), dtype = np.uint8)\n",
    "    \n",
    "    for i, image_file in enumerate(images):\n",
    "        image = cv2.imread(image_file, cv2.IMREAD_COLOR)\n",
    "        print(image.shape)\n",
    "        #image = image.reshape(50,100,3)\n",
    "        #print(image.shape)\n",
    "        data[i] = image.T\n",
    "        \n",
    "        #if i % 1 == 0:\n",
    "            #print ('Processed {} of {}'.format(i, count))\n",
    "            \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "id": "w_vgkyvNREeZ",
    "outputId": "53166582-f4cc-4208-b419-9491145f7360"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 2, 3],\n",
       "       [4, 5, 6],\n",
       "       [7, 8, 9]])"
      ]
     },
     "execution_count": 19,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.append([[1, 2, 3], [4, 5, 6]], [[7, 8, 9]], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8OlytEBSSDK5"
   },
   "outputs": [],
   "source": [
    "v=[1]\n",
    "v.append(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "_CQgQy2_SLRG",
    "outputId": "12f82253-7f3b-4130-90ce-4da2ea1153a8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2]"
      ]
     },
     "execution_count": 21,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rKNVXipvOp-v"
   },
   "outputs": [],
   "source": [
    "X_train=[]\n",
    "for i,mouth in enumerate(mouths):\n",
    "  print(i)\n",
    "  print(mouth)\n",
    "  train_images = [mouth + i for i in os.listdir(mouth)]\n",
    "  train = prep_data(train_images)\n",
    "  train=train.reshape(-1,100,50,3)\n",
    "  #train=np.expand_dims(train,0)\n",
    "  \n",
    "  X_train.append(train)\n",
    "  \n",
    "X_train = np.asarray(X_train)\n",
    "X_train = X_train.astype('float32')\n",
    "X_train /= 255\n",
    "#X_train=np.array(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RY19-MAvmFbr"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "TRAIN_DIR='output/mouth/'\n",
    "train_images = [TRAIN_DIR + i for i in os.listdir(TRAIN_DIR)]\n",
    "\n",
    "TRAIN_DIR1='output/mouth1/'\n",
    "train_images1 = [TRAIN_DIR1 + i for i in os.listdir(TRAIN_DIR1)]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "  \n",
    "\n",
    "train1= prep_data(train_images1)\n",
    "\n",
    "\n",
    "train1=train1.reshape(-1,100,50,3)\n",
    "\n",
    "\n",
    "train1=np.expand_dims(train1,0)\n",
    "train=np.concatenate((train,train1))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eZdK2vDFnU1c"
   },
   "outputs": [],
   "source": [
    "from keras.preprocessing.text import Tokenizer \n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "files=['swwp2s.align','priazn.align']\n",
    "def prep_text(files):\n",
    "  sent=[]\n",
    "  for file in files:\n",
    "    f = open(file, \"r\")\n",
    "    dummy=[line.split()[-1] for line in f] #-1 coz that's the word we want, 0 and 1 have timestamps\n",
    "    #print(dummy)\n",
    "    dummy[0]='<start>'\n",
    "    dummy[-1]='<end>'\n",
    "    sent.append(dummy)\n",
    "  return sent\n",
    "\n",
    "sent=prep_text(files)\n",
    "tokenizer= tf.keras.preprocessing.text.Tokenizer(oov_token=\"<unk>\", \n",
    "                                                  filters='!\"#$%&()*+.,-/:;=?@[\\]^_`{|}~ ')\n",
    "tokenizer.fit_on_texts(sent)\n",
    "sseq = tokenizer.texts_to_sequences(sent)\n",
    "dec_input=np.asarray(sseq)\n",
    "decoder_input_data=dec_input.astype('int32')\n",
    "\"\"\"\n",
    "decoder_target_data=np.zeros((dec_input.shape[0], dec_input.shape[1], len(tokenizer.word_index)+1),dtype='float32')\n",
    "for i,line in enumerate(sent):\n",
    "  for t, word in enumerate(line):\n",
    "    # decoder_target_data is ahead of decoder_input_data by one timestep\n",
    "    if t > 0:\n",
    "      #print(i,line)\n",
    "      #print(t,word)\n",
    "      # decoder_target_data will be ahead by one timestep\n",
    "      # and will not include the start character.\n",
    "      decoder_target_data[i, t - 1, tokenizer.word_index[word]] = 1.\n",
    "      #print(decoder_target_data)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "yLcbbYdAAlsC",
    "outputId": "9a25522b-f358-4621-bac7-72dbc466cdfd"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 133,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(decoder_input_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WnnE3b7dB6M3"
   },
   "outputs": [],
   "source": [
    "tokenizer.word_index['<pad>'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "C-lS74Wv9CaC",
    "outputId": "e76b49be-88f1-4e91-ba64-a7a351814023"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16"
      ]
     },
     "execution_count": 7,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tokenizer.word_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Z2k8clQv87K_"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GINA60sLnyuj"
   },
   "outputs": [],
   "source": [
    "dataset = tf.data.Dataset.from_tensor_slices((X_train, decoder_input_data))\n",
    "dataset = dataset.batch(BATCH_SIZE, drop_remainder=True)   #1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "vPWlVJv5oWPz",
    "outputId": "0e547cb3-672e-41c8-a47c-56b8afb0a207"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<DatasetV1Adapter shapes: ((2, 75, 100, 50, 3), (2, 8)), types: (tf.float32, tf.int32)>"
      ]
     },
     "execution_count": 120,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9mrneVGlwYok"
   },
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xLmM6gwTRruC"
   },
   "source": [
    "## Make dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "a8esSJtTdw8G"
   },
   "outputs": [],
   "source": [
    "def max_length(tensor):\n",
    "    return max(len(t) for t in tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "HmFshJ8Tdnvi",
    "outputId": "c5241538-b365-4896-dbdb-0f73f5148d2b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "54"
      ]
     },
     "execution_count": 27,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_length(sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DaJ9sMhUwmHA"
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 2\n",
    "BUFFER_SIZE = len(X_train)\n",
    "N_BATCH = BUFFER_SIZE//BATCH_SIZE\n",
    "embedding_dim = 50\n",
    "units = 256\n",
    "vocab_size = len(tokenizer.word_index)\n",
    "max_length_targ=max_length(sent)-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bL3SX2Uswmw2"
   },
   "outputs": [],
   "source": [
    "dataset = tf.data.Dataset.from_tensor_slices((X_train, decoder_input_data)).shuffle(BUFFER_SIZE)\n",
    "dataset = dataset.batch(BATCH_SIZE, drop_remainder=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fenutn-tRuWZ"
   },
   "source": [
    "## Make Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ifQUihfXoa7j"
   },
   "outputs": [],
   "source": [
    "def gru(units):\n",
    "  # If you have a GPU, we recommend using the CuDNNGRU layer (it provides a \n",
    "  # significant speedup).\n",
    "  if tf.test.is_gpu_available():\n",
    "    return tf.keras.layers.CuDNNGRU(units, \n",
    "                                    return_sequences=True, \n",
    "                                    return_state=True, \n",
    "                                    recurrent_initializer='glorot_uniform')\n",
    "  else:\n",
    "    return tf.keras.layers.GRU(units, \n",
    "                               return_sequences=True, \n",
    "                               return_state=True, \n",
    "                               recurrent_activation='sigmoid', \n",
    "                               recurrent_initializer='glorot_uniform')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "26sRmVto4d1E"
   },
   "outputs": [],
   "source": [
    "def lstm(units):\n",
    "  # If you have a GPU, we recommend using the CuDNNGRU layer (it provides a \n",
    "  # significant speedup).\n",
    "  if tf.test.is_gpu_available():\n",
    "    return tf.keras.layers.CuDNNLSTM(units, \n",
    "                                    return_sequences=True, \n",
    "                                    return_state=True, \n",
    "                                    recurrent_initializer='glorot_uniform')\n",
    "  else:\n",
    "    return tf.keras.layers.LSTM(units, \n",
    "                               return_sequences=True, \n",
    "                               return_state=True, \n",
    "                               recurrent_activation='sigmoid', \n",
    "                               recurrent_initializer='glorot_uniform')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZCAA1RtppFSc"
   },
   "outputs": [],
   "source": [
    "class Encoder(tf.keras.Model):\n",
    "    # Since we have already extracted the features and dumped it using pickle\n",
    "    # This encoder passes those features through a Fully connected layer\n",
    "    def __init__(self,enc_units, batch_sz):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.batch_sz = batch_sz\n",
    "        self.enc_units = enc_units\n",
    "        # shape after fc == (batch_size, 64, embedding_dim)\n",
    "        self.zero1= tf.keras.layers.ZeroPadding3D(padding=(1,2,2))\n",
    "        self.zero2= tf.keras.layers.ZeroPadding3D(padding=(1,2,2))\n",
    "        self.zero3= tf.keras.layers.ZeroPadding3D(padding=(1,1,1))\n",
    "        \n",
    "        self.conv1=tf.keras.layers.Conv3D(filters=32, kernel_size=(3,5,5), strides=(1,2,2), kernel_initializer='he_normal')\n",
    "        self.conv2=tf.keras.layers.Conv3D(filters=64, kernel_size=(3,5,5), strides=(1,1,1), kernel_initializer='he_normal')\n",
    "        self.conv3=tf.keras.layers.Conv3D(filters=96, kernel_size=(3,3,3), strides=(1,1,1), kernel_initializer='he_normal')\n",
    "        \n",
    "        \n",
    "        self.bn1=tf.keras.layers.BatchNormalization()\n",
    "        self.bn2=tf.keras.layers.BatchNormalization()\n",
    "        self.bn3=tf.keras.layers.BatchNormalization()\n",
    "        \n",
    "        self.spd1=tf.keras.layers.SpatialDropout3D(0.5)\n",
    "        self.spd2=tf.keras.layers.SpatialDropout3D(0.5)\n",
    "        self.spd3=tf.keras.layers.SpatialDropout3D(0.5)\n",
    "        \n",
    "        self.max_pool1=tf.keras.layers.MaxPool3D(pool_size=(1, 2, 2), strides=(1, 2, 2))   \n",
    "        self.max_pool2=tf.keras.layers.MaxPool3D(pool_size=(1, 2, 2), strides=(1, 2, 2)) \n",
    "        self.max_pool3=tf.keras.layers.MaxPool3D(pool_size=(1, 2, 2), strides=(1, 2, 2)) \n",
    "        \n",
    "        self.td=tf.keras.layers.TimeDistributed(tf.keras.layers.Flatten())\n",
    "        self.gru=gru(units=256)\n",
    "        \n",
    "        \n",
    "    def call(self, x,hidden):\n",
    "        \n",
    "        zero1 = self.zero1(x)\n",
    "        conv1 = self.conv1(zero1)\n",
    "        batc1 = self.bn1(conv1)\n",
    "        actv1 = tf.nn.relu(batc1)\n",
    "        drop1 = self.spd1(actv1)\n",
    "        maxp1 = self.max_pool1(drop1)\n",
    "\n",
    "        zero2 = self.zero2(maxp1)\n",
    "        conv2 = self.conv2(zero2)\n",
    "        batc2 = self.bn2(conv2)\n",
    "        actv2 = tf.nn.relu(batc2)\n",
    "        drop2 = self.spd2(actv2)\n",
    "        maxp2 = self.max_pool2(drop2)\n",
    "\n",
    "        zero3 = self.zero3(maxp2)\n",
    "        conv3 = self.conv3(zero3)\n",
    "        batc3 = self.bn3(conv3)\n",
    "        actv3 = tf.nn.relu(batc3)\n",
    "        drop3 = self.spd3(actv3)\n",
    "        maxp3 = self.max_pool3(drop3)\n",
    "\n",
    "        resh1 = self.td(maxp3)\n",
    "        output, state=self.gru(resh1,initial_state = hidden)\n",
    "\n",
    "        \n",
    "        return output, state\n",
    "      \n",
    "    def initialize_hidden_state(self):\n",
    "        return tf.zeros((self.batch_sz, self.enc_units))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9iLv_4fmFwGu"
   },
   "outputs": [],
   "source": [
    "class Decoder(tf.keras.Model):\n",
    "    def __init__(self, vocab_size, embedding_dim, dec_units, batch_sz):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.batch_sz = batch_sz\n",
    "        self.dec_units = dec_units\n",
    "        self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
    "        self.gru=gru(self.dec_units)\n",
    "        self.fc = tf.keras.layers.Dense(vocab_size)\n",
    "        \n",
    "        # used for attention\n",
    "        self.W1 = tf.keras.layers.Dense(self.dec_units)\n",
    "        self.W2 = tf.keras.layers.Dense(self.dec_units)\n",
    "        self.V = tf.keras.layers.Dense(1)\n",
    "        \n",
    "    def call(self, x, hidden, enc_output):\n",
    "        # enc_output shape == (batch_size, max_length, hidden_size)\n",
    "        \n",
    "        # hidden shape == (batch_size, hidden size)\n",
    "        # hidden_with_time_axis shape == (batch_size, 1, hidden size)\n",
    "        # we are doing this to perform addition to calculate the score\n",
    "        hidden_with_time_axis = tf.expand_dims(hidden, 1)\n",
    "        \n",
    "        # score shape == (batch_size, max_length, 1)\n",
    "        # we get 1 at the last axis because we are applying tanh(FC(EO) + FC(H)) to self.V\n",
    "        score = self.V(tf.nn.tanh(self.W1(enc_output) + self.W2(hidden_with_time_axis)))\n",
    "        \n",
    "        # attention_weights shape == (batch_size, max_length, 1) get alpha\n",
    "        attention_weights = tf.nn.softmax(score, axis=1)\n",
    "        \n",
    "        # context_vector shape after sum == (batch_size, hidden_size)\n",
    "        context_vector = attention_weights * enc_output\n",
    "        context_vector = tf.reduce_sum(context_vector, axis=1)\n",
    "        \n",
    "        # x shape after passing through embedding == (batch_size, 1, embedding_dim) coz 1st dec input is '<start>' i.e x of shape (bz,1)\n",
    "        x = self.embedding(x)\n",
    "        \n",
    "        # x shape after concatenation == (batch_size, 1, embedding_dim + hidden_size)\n",
    "        x = tf.concat([tf.expand_dims(context_vector, 1), x], axis=-1)\n",
    "        \n",
    "        # passing the concatenated vector to the GRU\n",
    "        output, state = self.gru(x)\n",
    "        \n",
    "        # output shape == (batch_size * 1, hidden_size)\n",
    "        output = tf.reshape(output, (-1, output.shape[2]))\n",
    "        \n",
    "        # output shape == (batch_size * 1, vocab)\n",
    "        x = self.fc(output)\n",
    "        \n",
    "        return x, state, attention_weights\n",
    "        \n",
    "    def initialize_hidden_state(self):\n",
    "        return tf.zeros((self.batch_sz, self.dec_units))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QoYuHMTMCume"
   },
   "outputs": [],
   "source": [
    "encoder = Encoder(units, BATCH_SIZE)\n",
    "decoder = Decoder(vocab_size, embedding_dim, units, BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "id": "14ldOrHWpmFM",
    "outputId": "571eba5a-e797-484f-bf1d-81569ebf26fb"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\noptimizer = tf.keras.optimizers.Adam()\\nloss_object = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\\n\\ndef loss_function(real, pred):\\n  mask = tf.math.logical_not(tf.math.equal(real, 0))\\n  loss_ = loss_object(real, pred)\\n\\n  mask = tf.cast(mask, dtype=loss_.dtype)\\n  loss_ *= mask\\n  \\n  return tf.reduce_mean(loss_)\\n'"
      ]
     },
     "execution_count": 61,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "optimizer = tf.keras.optimizers.Adam()\n",
    "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "\n",
    "def loss_function(real, pred):\n",
    "  mask = tf.math.logical_not(tf.math.equal(real, 0))\n",
    "  loss_ = loss_object(real, pred)\n",
    "\n",
    "  mask = tf.cast(mask, dtype=loss_.dtype)\n",
    "  loss_ *= mask\n",
    "  \n",
    "  return tf.reduce_mean(loss_)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1aCIaOS3Ijq5"
   },
   "outputs": [],
   "source": [
    "\n",
    "optimizer = tf.train.AdamOptimizer()\n",
    "\n",
    "# We are masking the loss calculated for padding\n",
    "def loss_function(real, pred):\n",
    "    mask = 1 - np.equal(real, 0)\n",
    "    loss_ = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=real, logits=pred) * mask\n",
    "    return tf.reduce_mean(loss_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Sj3jKUeyi5_u"
   },
   "source": [
    "#Checkpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_8uR9aGyi5RE"
   },
   "outputs": [],
   "source": [
    "checkpoint_dir = './training_checkpoints'\n",
    "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt\")\n",
    "checkpoint = tf.train.Checkpoint(optimizer=optimizer,\n",
    "                                 encoder=encoder,\n",
    "                                 decoder=decoder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2TbBrPErR6HJ"
   },
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "SdzeaFEBJZFB",
    "outputId": "6d4c2215-f350-4255-ac5a-9f79c1f2b63a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.13.1\n"
     ]
    }
   ],
   "source": [
    "from __future__ import absolute_import, division, print_function\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import unicodedata\n",
    "import re\n",
    "import numpy as np\n",
    "import os\n",
    "import time\n",
    "\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "R2mU5MlTYRt8"
   },
   "outputs": [],
   "source": [
    "# adding this in a separate cell because if you run the training cell \n",
    "# many times, the loss_plot array will be reset\n",
    "loss_plot = []\n",
    "train_accuracy_results = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aGQfMTBQWDxr"
   },
   "outputs": [],
   "source": [
    "#for (batch, (img_tensor, target)) in enumerate(dataset):\n",
    "  #print(target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "id": "VVhfB_fRokGB",
    "outputId": "b66ac004-a0a9-4568-e208-85fcf98405f0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"TPU_WORKER = 'grpc://' + os.environ['COLAB_TPU_ADDR']\\ntencoder = tf.contrib.tpu.keras_to_tpu_model(\\n    encoder,\\n    strategy=tf.contrib.tpu.TPUDistributionStrategy(\\n        tf.contrib.cluster_resolver.TPUClusterResolver(TPU_WORKER)))\\ntdecoder = tf.contrib.tpu.keras_to_tpu_model(\\n    decoder,\\n    strategy=tf.contrib.tpu.TPUDistributionStrategy(\\n        tf.contrib.cluster_resolver.TPUClusterResolver(TPU_WORKER)))\""
      ]
     },
     "execution_count": 66,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This address identifies the TPU we'll use when configuring TensorFlow.\n",
    "'''TPU_WORKER = 'grpc://' + os.environ['COLAB_TPU_ADDR']\n",
    "tencoder = tf.contrib.tpu.keras_to_tpu_model(\n",
    "    encoder,\n",
    "    strategy=tf.contrib.tpu.TPUDistributionStrategy(\n",
    "        tf.contrib.cluster_resolver.TPUClusterResolver(TPU_WORKER)))\n",
    "tdecoder = tf.contrib.tpu.keras_to_tpu_model(\n",
    "    decoder,\n",
    "    strategy=tf.contrib.tpu.TPUDistributionStrategy(\n",
    "        tf.contrib.cluster_resolver.TPUClusterResolver(TPU_WORKER)))'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 2057
    },
    "id": "p3RZbXHCIygI",
    "outputId": "8e0a7fcb-6c0f-4445-ae9a-e7d026ec27c9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 Batch 0 Loss 0.2775\n",
      "Epoch 1 Loss 0.165899, Accuracy: 46.296%\n",
      "Time taken for 1 epoch 36.26398301124573 sec\n",
      "\n",
      "Epoch 2 Batch 0 Loss 0.1169\n",
      "Epoch 2 Loss 0.157463, Accuracy: 46.296%\n",
      "Time taken for 1 epoch 35.55385184288025 sec\n",
      "\n",
      "Epoch 3 Batch 0 Loss 0.1624\n",
      "Epoch 3 Loss 0.158407, Accuracy: 45.947%\n",
      "Time taken for 1 epoch 35.646793365478516 sec\n",
      "\n",
      "Epoch 4 Batch 0 Loss 0.1383\n",
      "Epoch 4 Loss 0.163008, Accuracy: 46.925%\n",
      "Time taken for 1 epoch 35.627066135406494 sec\n",
      "\n",
      "Epoch 5 Batch 0 Loss 0.1078\n",
      "Epoch 5 Loss 0.150937, Accuracy: 46.820%\n",
      "Time taken for 1 epoch 34.95844006538391 sec\n",
      "\n",
      "Epoch 6 Batch 0 Loss 0.0944\n",
      "Epoch 6 Loss 0.151170, Accuracy: 46.052%\n",
      "Time taken for 1 epoch 37.39490079879761 sec\n",
      "\n",
      "Epoch 7 Batch 0 Loss 0.1741\n",
      "Epoch 7 Loss 0.149908, Accuracy: 46.052%\n",
      "Time taken for 1 epoch 35.135088205337524 sec\n",
      "\n",
      "Epoch 8 Batch 0 Loss 0.0951\n",
      "Epoch 8 Loss 0.147992, Accuracy: 46.751%\n",
      "Time taken for 1 epoch 35.734421253204346 sec\n",
      "\n",
      "Epoch 9 Batch 0 Loss 0.0656\n",
      "Epoch 9 Loss 0.139041, Accuracy: 46.925%\n",
      "Time taken for 1 epoch 35.029937505722046 sec\n",
      "\n",
      "Epoch 10 Batch 0 Loss 0.1147\n",
      "Epoch 10 Loss 0.138967, Accuracy: 46.541%\n",
      "Time taken for 1 epoch 35.72042179107666 sec\n",
      "\n",
      "Epoch 11 Batch 0 Loss 0.0822\n",
      "Epoch 11 Loss 0.139298, Accuracy: 46.401%\n",
      "Time taken for 1 epoch 35.04000782966614 sec\n",
      "\n",
      "Epoch 12 Batch 0 Loss 0.0914\n",
      "Epoch 12 Loss 0.149703, Accuracy: 46.261%\n",
      "Time taken for 1 epoch 35.29850792884827 sec\n",
      "\n",
      "Epoch 13 Batch 0 Loss 0.1543\n",
      "Epoch 13 Loss 0.148538, Accuracy: 45.632%\n",
      "Time taken for 1 epoch 35.67613506317139 sec\n",
      "\n",
      "Epoch 14 Batch 0 Loss 0.1447\n",
      "Epoch 14 Loss 0.137506, Accuracy: 46.716%\n",
      "Time taken for 1 epoch 35.08514428138733 sec\n",
      "\n",
      "Epoch 15 Batch 0 Loss 0.0536\n",
      "Epoch 15 Loss 0.127012, Accuracy: 47.554%\n",
      "Time taken for 1 epoch 36.5640013217926 sec\n",
      "\n",
      "Epoch 16 Batch 0 Loss 0.1245\n",
      "Epoch 16 Loss 0.123283, Accuracy: 47.729%\n",
      "Time taken for 1 epoch 35.029582500457764 sec\n",
      "\n",
      "Epoch 17 Batch 0 Loss 0.1596\n",
      "Epoch 17 Loss 0.119827, Accuracy: 48.218%\n",
      "Time taken for 1 epoch 36.59897422790527 sec\n",
      "\n",
      "Epoch 18 Batch 0 Loss 0.0791\n",
      "Epoch 18 Loss 0.118938, Accuracy: 47.904%\n",
      "Time taken for 1 epoch 35.1740300655365 sec\n",
      "\n",
      "Epoch 19 Batch 0 Loss 0.1038\n",
      "Epoch 19 Loss 0.126106, Accuracy: 47.939%\n",
      "Time taken for 1 epoch 36.04116749763489 sec\n",
      "\n",
      "Epoch 20 Batch 0 Loss 0.0622\n",
      "Epoch 20 Loss 0.118818, Accuracy: 47.310%\n",
      "Time taken for 1 epoch 35.336934089660645 sec\n",
      "\n",
      "Epoch 21 Batch 0 Loss 0.0782\n",
      "Epoch 21 Loss 0.116713, Accuracy: 46.960%\n",
      "Time taken for 1 epoch 35.37958240509033 sec\n",
      "\n",
      "Epoch 22 Batch 0 Loss 0.0942\n",
      "Epoch 22 Loss 0.116993, Accuracy: 47.170%\n",
      "Time taken for 1 epoch 35.658626079559326 sec\n",
      "\n",
      "Epoch 23 Batch 0 Loss 0.0646\n",
      "Epoch 23 Loss 0.110447, Accuracy: 47.659%\n",
      "Time taken for 1 epoch 35.65476965904236 sec\n",
      "\n",
      "Epoch 24 Batch 0 Loss 0.0570\n",
      "Epoch 24 Loss 0.113607, Accuracy: 47.065%\n",
      "Time taken for 1 epoch 36.81496834754944 sec\n",
      "\n",
      "Epoch 25 Batch 0 Loss 0.0994\n",
      "Epoch 25 Loss 0.117037, Accuracy: 46.960%\n",
      "Time taken for 1 epoch 35.84139680862427 sec\n",
      "\n",
      "Epoch 26 Batch 0 Loss 0.1644\n",
      "Epoch 26 Loss 0.110946, Accuracy: 47.379%\n",
      "Time taken for 1 epoch 35.949270725250244 sec\n",
      "\n",
      "Epoch 27 Batch 0 Loss 0.0665\n",
      "Epoch 27 Loss 0.108007, Accuracy: 47.484%\n",
      "Time taken for 1 epoch 34.85666847229004 sec\n",
      "\n",
      "Epoch 28 Batch 0 Loss 0.1127\n",
      "Epoch 28 Loss 0.106458, Accuracy: 48.288%\n",
      "Time taken for 1 epoch 35.7715790271759 sec\n",
      "\n",
      "Epoch 29 Batch 0 Loss 0.0730\n",
      "Epoch 29 Loss 0.130667, Accuracy: 47.554%\n",
      "Time taken for 1 epoch 34.71767568588257 sec\n",
      "\n",
      "Epoch 30 Batch 0 Loss 0.0906\n",
      "Epoch 30 Loss 0.133131, Accuracy: 47.589%\n",
      "Time taken for 1 epoch 34.77645421028137 sec\n",
      "\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 30 #150\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    start = time.time()\n",
    "    hidden = encoder.initialize_hidden_state()\n",
    "    total_loss = 0\n",
    "    epoch_accuracy = tf.contrib.eager.metrics.Accuracy()#accuracy #Change here for without Nightly\n",
    "    \n",
    "    for (batch, (img_tensor, target)) in enumerate(dataset):\n",
    "        loss = 0\n",
    "        \n",
    "        pred_list=[]#accuracy\n",
    "        with tf.GradientTape() as tape:\n",
    "            enc_output, enc_hidden = encoder(img_tensor, hidden)\n",
    "            \n",
    "            dec_hidden = enc_hidden\n",
    "            \n",
    "            dec_input = tf.expand_dims([tokenizer.word_index['<start>']] * BATCH_SIZE, 1)       \n",
    "            \n",
    "            # Teacher forcing - feeding the target as the next input\n",
    "            for t in range(1, target.shape[1]):\n",
    "                # passing enc_output to the decoder\n",
    "                predictions, dec_hidden, _ = decoder(dec_input, dec_hidden, enc_output)\n",
    "                pred_list.append(tf.argmax(predictions, axis=1, output_type=tf.int32))#accuracy\n",
    "                \n",
    "                loss += loss_function(target[:, t], predictions)\n",
    "                \n",
    "                # using teacher forcing\n",
    "                dec_input = tf.expand_dims(target[:, t], 1)\n",
    "        \n",
    "        total_loss += (loss / int(target.shape[1]))\n",
    "        \n",
    "        variables = encoder.variables + decoder.variables\n",
    "        \n",
    "        gradients = tape.gradient(loss, variables) \n",
    "        \n",
    "        optimizer.apply_gradients(zip(gradients, variables))#, tf.train.get_or_create_global_step()\n",
    "\n",
    "        epoch_accuracy(np.asarray(pred_list).T, target[:,1:]) #accuracy\n",
    "        \n",
    "        if batch % 100 == 0:\n",
    "            print ('Epoch {} Batch {} Loss {:.4f}'.format(epoch + 1, \n",
    "                                                          batch, \n",
    "                                                          loss.numpy() / int(target.shape[1])))\n",
    "    # storing the epoch end loss value to plot later\n",
    "    loss_plot.append(total_loss / N_BATCH)\n",
    "    train_accuracy_results.append(epoch_accuracy.result())\n",
    "    \n",
    "    # saving (checkpoint) the model every 2 epochs\n",
    "    if (epoch + 1) % 10 == 0:\n",
    "      checkpoint.save(file_prefix = checkpoint_prefix)\n",
    "    \n",
    "    print ('Epoch {} Loss {:.6f}, Accuracy: {:.3%}'.format(epoch + 1, \n",
    "                                                           total_loss/N_BATCH,\n",
    "                                                           epoch_accuracy.result()))#accuracy\n",
    "    print ('Time taken for 1 epoch {} sec\\n'.format(time.time() - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 295
    },
    "id": "YmDSa-4eJ6LC",
    "outputId": "a654546a-0e3d-4920-88c1-dbeacbd68536"
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEWCAYAAACJ0YulAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nrkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(loss_plot)\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Loss Plot')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 295
    },
    "id": "usfj16p7J6f8",
    "outputId": "7533da6d-2778-4fd3-90f1-baccd2c912b1"
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEWCAYAAACJ0YulAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nlQegAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(train_accuracy_results)\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Loss Plot')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "B_fCOU6V2fMB"
   },
   "source": [
    "# Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "72Vnw_KZ2hMt"
   },
   "outputs": [],
   "source": [
    "def evaluate(img_tensor):\n",
    "    hidden = [tf.zeros((1, units))] #?\n",
    "    img_tensor=tf.convert_to_tensor(img_tensor)\n",
    "    img_tensor=tf.expand_dims(img_tensor,0) #start?\n",
    "    enc_out, enc_hidden = encoder(img_tensor, hidden)\n",
    "    \n",
    "    dec_input = tf.expand_dims([tokenizer.word_index['<start>']], 0)\n",
    "    dec_hidden = enc_hidden #?\n",
    "    \n",
    "    result = ''\n",
    "\n",
    "    for i in range(max_length_targ):\n",
    "        predictions, dec_hidden, attention_weights = decoder(dec_input, dec_hidden, enc_out)\n",
    "\n",
    "        predicted_id = tf.argmax(predictions[0]).numpy()\n",
    "        result += tokenizer.index_word[predicted_id] + ' '\n",
    "\n",
    "\n",
    "        if tokenizer.index_word[predicted_id] == '<end>':\n",
    "            return result\n",
    "\n",
    "        dec_input = tf.expand_dims([predicted_id], 0)\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 972
    },
    "id": "_4mRhglT2iHE",
    "outputId": "914b3b30-ffe3-4a01-8f0e-fd8bef7a0ec0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted : that there's an interesting problem but they don't quite have the tools yet to discover them they spend all this time <end>  || True ['<start>', 'TO', 'SHOW', 'IT', 'TO', 'YOU', 'NOT', 'BECAUSE', 'I', 'WANT', 'TO', 'GIVE', 'YOU', 'THE', 'KIND', 'OF', 'STARBUCKS', 'TOUR', 'OF', 'HISTORIC', 'ENGLAND', 'BUT', '<end>']\n",
      "Predicted : morning and the news has just broken about this satellite that's now orbiting the planet from a known location on the planet from a known location on the planet from a known location on the planet from a known location on the planet from a known location on the planet from a  || True ['<start>', 'BEFORE', 'THE', 'SPREAD', 'OF', 'COFFEE', 'AND', 'TEA', 'THROUGH', 'BRITISH', 'CULTURE', 'WHAT', 'PEOPLE', 'DRANK', 'BOTH', 'ELITE', 'AND', 'MASS', 'FOLKS', 'DRANK', '<end>']\n",
      "Predicted : a lot of these values and it's just wonderful kind of tale of innovation and how it happens in unlikely <end>  || True ['<start>', 'DRINKING', 'ALL', 'DAY', 'AND', 'THEN', 'YOU', 'SWITCHED', 'FROM', 'A', 'DEPRESSANT', 'TO', 'A', 'STIMULANT', 'IN', 'YOUR', '<end>']\n",
      "Predicted : them together into new forms and we create something new that's really where innovation <end>  || True ['<start>', 'WHERE', 'PEOPLE', 'WOULD', 'GET', 'TOGETHER', 'FROM', 'DIFFERENT', 'BACKGROUNDS', 'DIFFERENT', 'FIELDS', 'OF', 'EXPERTISE', '<end>']\n",
      "Predicted : that in fact the kind of network patterns of the human <end>  || True ['<start>', 'IT', 'WAS', 'A', 'SPACE', 'AS', 'MATT', 'RIDLEY', 'TALKED', 'ABOUT', 'WHERE', 'IDEAS', 'COULD', 'HAVE', 'SEX', 'THIS', 'WAS', 'THEIR', 'CONJUGAL', 'BED', 'IN', 'A', '<end>']\n",
      "Predicted : spending a lot of time thinking about coffeehouses for the last five years because i've been kind of on this quest to investigate this <end>  || True ['<start>', 'SPENDING', 'A', 'LOT', 'OF', 'TIME', 'THINKING', 'ABOUT', 'COFFEEHOUSES', 'FOR', 'THE', 'LAST', 'FIVE', 'YEARS', 'BECAUSE', \"I'VE\", 'BEEN', 'KIND', 'OF', 'ON', 'THIS', 'QUEST', 'TO', 'INVESTIGATE', 'THIS', '<end>']\n",
      "Predicted : of different ideas that are together different backgrounds different interests jostling with each other bouncing off each other that environment is in fact the environment that leads to <end>  || True ['<start>', 'OF', 'CREATIVITY', 'AND', 'WHAT', \"I'VE\", 'DONE', 'IS', \"I'VE\", 'LOOKED', 'AT', 'BOTH', 'ENVIRONMENTS', 'LIKE', 'THE', 'COFFEEHOUSE', \"I'VE\", 'LOOKED', 'AT', 'MEDIA', 'ENVIRONMENTS', 'LIKE', 'THE', 'WORLD', 'WIDE', 'WEB', 'THAT', 'HAVE', 'BEEN', 'EXTRAORDINARILY', 'INNOVATIVE', '<end>']\n",
      "Predicted : that in fact the kind of network patterns of the human <end>  || True ['<start>', 'IS', 'SHARED', 'PATTERNS', 'KIND', 'OF', 'SIGNATURE', 'BEHAVIOR', 'THAT', 'SHOWS', 'UP', 'AGAIN', 'AND', 'AGAIN', 'IN', 'ALL', 'OF', 'THESE', '<end>']\n",
      "Predicted : a whole system of spare parts and you don't have the on the ground expertise to fix this 40000 piece of equipment and <end>  || True ['<start>', 'RECURRING', 'PATTERNS', 'THAT', 'WE', 'CAN', 'LEARN', 'FROM', 'THAT', 'WE', 'CAN', 'TAKE', 'AND', 'KIND', 'OF', 'APPLY', 'TO', 'OUR', 'OWN', 'LIVES', 'OR', 'OUR', 'OWN', 'ORGANIZATIONS', 'OR', 'OUR', 'OWN', 'ENVIRONMENTS', '<end>']\n",
      "Predicted : that there's an interesting problem but they don't quite have the tools yet to discover them they spend all this time <end>  || True ['<start>', 'METAPHORS', 'AND', 'LANGUAGE', 'STEERS', 'US', 'TOWARDS', 'CERTAIN', 'CONCEPTS', 'OF', 'IDEA', 'CREATION', 'WE', '<end>']\n",
      "Predicted : them together into new forms and we create something new that's really where innovation <end>  || True ['<start>', 'WONDERFUL', 'ILLUMINATING', 'MOMENT', 'BUT', 'IN', 'FACT', 'WHAT', '<end>']\n",
      "Predicted : that that's an interesting idea and it turns <end>  || True ['<start>', 'NETWORK', 'OF', 'NEURONS', 'FIRING', 'IN', 'SYNC', 'WITH', 'EACH', 'OTHER', 'INSIDE', 'YOUR', 'BRAIN', \"IT'S\", 'A', 'NEW', 'CONFIGURATION', '<end>']\n",
      "Predicted : a whole system of spare parts and you don't have the on the ground expertise to fix this 40000 piece of equipment and <end>  || True ['<start>', 'BEFORE', 'AND', 'THE', 'QUESTION', 'IS', 'HOW', 'DO', 'YOU', 'GET', 'YOUR', 'BRAIN', 'INTO', 'ENVIRONMENTS', 'WHERE', 'THESE', 'NEW', 'NETWORKS', 'ARE', 'GOING', 'TO', 'BE', 'MORE', 'LIKELY', 'TO', 'FORM', '<end>']\n",
      "Predicted : a lot of these values and it's just wonderful kind of tale of innovation and how it happens in unlikely <end>  || True ['<start>', 'THAT', 'IN', 'FACT', 'THE', 'KIND', 'OF', 'NETWORK', 'PATTERNS', 'OF', 'THE', 'OUTSIDE', 'WORLD', 'MIMIC', 'LOT', 'OF', 'THE', 'NETWORK', 'PATTERNS', 'OF', 'THE', 'INTERNAL', 'WORLD', 'OF', 'THE', 'HUMAN', '<end>']\n",
      "Predicted : morning and the news has just broken about this satellite that's now orbiting the planet from a known location on the planet from a known location on the planet from a known location on the planet from a known location on the planet from a known location on the planet from a  || True ['<start>', 'TO', 'TACKLE', 'THIS', 'REALLY', 'PRESSING', 'PROBLEM', 'OF', 'YOU', 'KNOW', 'THE', 'TERRIBLE', 'PROBLEMS', 'WE', 'HAVE', 'WITH', 'INFANT', 'MORTALITY', 'RATES', 'IN', 'THE', 'DEVELOPING', 'WORLD', '<end>']\n",
      "Predicted : a bunch of satellites and use it to track our submarines and figure out their location in a <end>  || True ['<start>', \"THAT'S\", 'VERY', 'FRUSTRATING', 'ABOUT', 'THIS', 'IS', 'THAT', 'WE', 'KNOW', 'BY', 'GETTING', 'MODERN', 'NEONATAL', 'INCUBATORS', 'INTO', 'ANY', '<end>']\n",
      "Predicted : premature babies warm basically it's very simple we can halve infant mortality rates in those environments so the technology is there these are standard in all the industrialized worlds <end>  || True ['<start>', 'PREMATURE', 'BABIES', 'WARM', 'BASICALLY', \"IT'S\", 'VERY', 'SIMPLE', 'WE', 'CAN', 'HALVE', 'INFANT', 'MORTALITY', 'RATES', 'IN', 'THOSE', 'ENVIRONMENTS', 'SO', 'THE', 'TECHNOLOGY', 'IS', 'THERE', 'THESE', 'ARE', 'STANDARD', 'IN', 'ALL', 'THE', 'INDUSTRIALIZED', 'WORLDS', '<end>']\n",
      "Predicted : that in fact the kind of equipment and <end>  || True ['<start>', 'GREAT', 'FOR', 'YEAR', 'OR', 'TWO', 'YEARS', 'AND', 'THEN', 'SOMETHING', 'WILL', 'GO', 'WRONG', 'AND', 'IT', 'WILL', 'BREAK', 'AND', 'IT', 'WILL', 'REMAIN', 'BROKEN', 'FOREVER', '<end>']\n",
      "Predicted : a bunch of satellites and use it to track our submarines and figure out their location in a <end>  || True ['<start>', 'A', 'WHOLE', 'SYSTEM', 'OF', 'SPARE', 'PARTS', 'AND', 'YOU', \"DON'T\", 'HAVE', 'THE', 'ON', 'THE', 'GROUND', 'EXPERTISE', 'TO', 'FIX', 'THIS', '40000', 'PIECE', 'OF', 'EQUIPMENT', 'AND', '<end>']\n",
      "Predicted : and see what are the abundant resources in all a lot of keeping their cars on the signal because the soviets made sputnik very easy to <end>  || True ['<start>', 'AND', 'SEE', 'WHAT', 'ARE', 'THE', 'ABUNDANT', 'RESOURCES', 'IN', 'THESE', 'DEVELOPING', 'WORLD', 'CONTEXTS', 'AND', 'WHAT', 'THEY', 'NOTICED', 'WAS', 'THEY', \"DON'T\", 'HAVE', 'A', 'LOT', 'OF', 'DVRS', 'THEY', \"DON'T\", 'HAVE', 'A', 'LOT', 'OF', 'MICROWAVES', 'BUT', 'THEY', 'SEEM', 'TO', 'DO', 'A', 'PRETTY', 'GOOD', 'JOB', 'OF', 'KEEPING', 'THEIR', 'CARS', 'ON', 'THE', 'ROAD', '<end>']\n",
      "Predicted : forerunner on the expertise to think could we build a neonatal incubator that's built entirely out of automobile <end>  || True ['<start>', 'FORERUNNER', 'ON', 'THE', 'STREET', 'IN', 'ALL', 'THESE', 'PLACES', 'THEY', 'SEEM', 'TO', 'HAVE', 'THE', 'EXPERTISE', 'TO', 'KEEP', 'CARS', 'WORKING', 'SO', 'THEY', 'STARTED', 'TO', 'THINK', 'COULD', 'WE', 'BUILD', 'A', 'NEONATAL', 'INCUBATOR', \"THAT'S\", 'BUILT', 'ENTIRELY', 'OUT', 'OF', 'AUTOMOBILE', '<end>']\n",
      "Predicted : that there's an interesting problem but they don't quite have the tools yet to discover them they spend all this time <end>  || True ['<start>', 'THINK', 'OUR', 'BREAKTHROUGH', 'IDEAS', 'YOU', 'KNOW', 'ARE', 'LIKE', 'THAT', '40000', 'BRAND', 'NEW', 'INCUBATOR', 'STATE', 'OF', 'THE', 'ART', '<end>']\n",
      "Predicted : them together into new forms and we create something new that's really where innovation <end>  || True ['<start>', 'THEM', 'TOGETHER', 'INTO', 'NEW', 'FORMS', 'AND', 'WE', 'CREATE', 'SOMETHING', 'NEW', \"THAT'S\", 'REALLY', 'WHERE', 'INNOVATION', '<end>']\n",
      "Predicted : that are more innovative we have to look <end>  || True ['<start>', 'THE', 'SPACES', 'THAT', 'HAVE', 'HISTORICALLY', 'LED', 'TO', 'INNOVATION', 'TEND', 'TO', 'LOOK', '<end>']\n",
      "Predicted : that are more innovative we have to build spaces that strangely enough look a little bit more like <end>  || True ['<start>', 'THAT', 'ARE', 'MORE', 'INNOVATIVE', 'WE', 'HAVE', 'TO', 'BUILD', 'SPACES', 'THAT', 'STRANGELY', 'ENOUGH', 'LOOK', 'A', 'LITTLE', 'BIT', 'MORE', 'LIKE', '<end>']\n",
      "Predicted : they've got the idea what happened actually when dunbar kind of the important breakthrough ideas did not happen alone in the last day or last week <end>  || True ['<start>', 'TO', 'A', 'BUNCH', 'OF', 'SCIENCE', 'LABS', 'AROUND', 'THE', 'WORLD', 'AND', 'VIDEOTAPED', 'EVERYONE', 'AS', 'THEY', 'WERE', 'DOING', 'EVERY', 'LITTLE', 'BIT', 'OF', 'THEIR', 'JOB', 'SO', 'WHEN', 'THEY', 'WERE', 'SITTING', 'IN', 'FRONT', 'OF', 'THE', 'MICROSCOPE', 'WHEN', 'THEY', 'WERE', 'TALKING', 'TO', 'THEIR', 'COLLEAGUE', 'AT', 'THE', 'WATER', 'COOLER', 'AND', 'ALL', 'THESE', 'THINGS', 'AND', '<end>']\n",
      "Predicted : they've got the idea what happened actually when dunbar kind of the important breakthrough ideas did not happen alone in the lab in front of the important breakthrough ideas did not happen alone in the lab in front of the important breakthrough ideas did not happen alone in the lab in front  || True ['<start>', \"THEY'VE\", 'GOT', 'THE', 'IDEA', 'WHAT', 'HAPPENED', 'ACTUALLY', 'WHEN', 'DUNBAR', 'KIND', 'OF', 'LOOKED', 'AT', 'THE', 'TAPE', 'IS', 'THAT', 'IN', 'FACT', 'ALMOST', 'ALL', 'OF', 'THE', 'IMPORTANT', 'BREAKTHROUGH', 'IDEAS', 'DID', 'NOT', 'HAPPEN', 'ALONE', 'IN', 'THE', 'LAB', 'IN', 'FRONT', 'OF', 'THE', '<end>']\n",
      "Predicted : is that darwin in a sense had the idea he had the concept but was unable of fully thinking it yet and that is actually how great ideas often <end>  || True ['<start>', 'OF', 'DIFFERENT', 'IDEAS', 'THAT', 'ARE', 'TOGETHER', 'DIFFERENT', 'BACKGROUNDS', 'DIFFERENT', 'INTERESTS', 'JOSTLING', 'WITH', 'EACH', 'OTHER', 'BOUNCING', 'OFF', 'EACH', 'OTHER', 'THAT', 'ENVIRONMENT', 'IS', 'IN', 'FACT', 'THE', 'ENVIRONMENT', 'THAT', 'LEADS', 'TO', '<end>']\n",
      "Predicted : that there's an interesting problem but they don't quite have the tools yet to discover them they spend all this time <end>  || True ['<start>', 'THAT', \"THERE'S\", 'AN', 'INTERESTING', 'PROBLEM', 'BUT', 'THEY', \"DON'T\", 'QUITE', 'HAVE', 'THE', 'TOOLS', 'YET', 'TO', 'DISCOVER', 'THEM', 'THEY', 'SPEND', 'ALL', 'THIS', 'TIME', '<end>']\n",
      "Predicted : that there's an interesting problem but they don't quite have the tools yet to discover them they spend all this time <end>  || True ['<start>', 'ACTUALLY', 'ON', 'POPULATION', 'AND', 'ALL', 'OF', 'A', 'SUDDEN', 'THE', 'BASIC', 'ALGORITHM', 'OF', 'NATURAL', 'SELECTION', 'KIND', 'OF', 'POPS', 'INTO', 'HIS', 'HEAD', 'AND', 'HE', '<end>']\n",
      "Predicted : is that darwin in a sense had the idea he had the concept but was unable of fully thinking it yet and that is actually how great ideas often <end>  || True ['<start>', 'IS', 'THAT', 'DARWIN', 'IN', 'A', 'SENSE', 'HAD', 'THE', 'IDEA', 'HE', 'HAD', 'THE', 'CONCEPT', 'BUT', 'WAS', 'UNABLE', 'OF', 'FULLY', 'THINKING', 'IT', 'YET', 'AND', 'THAT', 'IS', 'ACTUALLY', 'HOW', 'GREAT', 'IDEAS', 'OFTEN', '<end>']\n",
      "Predicted : an excellent idea for our organization it will be useful in 2020 could you just give me some time to do that now couple of companies like google they have innovation time off 20 percent time where in a <end>  || True ['<start>', 'AN', 'EXCELLENT', 'IDEA', 'FOR', 'OUR', 'ORGANIZATION', 'IT', 'WILL', 'BE', 'USEFUL', 'IN', '2020', 'COULD', 'YOU', 'JUST', 'GIVE', 'ME', 'SOME', 'TIME', 'TO', 'DO', 'THAT', 'NOW', 'COUPLE', 'OF', 'COMPANIES', 'LIKE', 'GOOGLE', 'THEY', 'HAVE', 'INNOVATION', 'TIME', 'OFF', '20', 'PERCENT', 'TIME', 'WHERE', 'IN', 'A', '<end>']\n",
      "Predicted : that that's an interesting idea and it turns <end>  || True ['<start>', 'HUNCH', 'CULTIVATING', 'MECHANISMS', 'IN', 'AN', 'ORGANIZATION', 'BUT', \"THAT'S\", 'A', '<end>']\n",
      "Predicted : morning and the news has just broken about this satellite that's now orbiting the planet from a known location on the planet from a known location on the planet from a known location on the planet from a known location on the planet from a known location on the planet from a  || True ['<start>', 'OF', 'AN', 'IDEA', 'SOMEBODY', 'ELSE', 'HAS', 'THE', 'OTHER', 'HALF', 'AND', 'IF', \"YOU'RE\", 'IN', 'THE', 'RIGHT', 'ENVIRONMENT', 'THEY', 'TURN', 'INTO', 'SOMETHING', 'LARGER', 'THAN', 'THE', 'SUM', 'OF', 'THEIR', 'PARTS', 'SO', 'IN', 'A', 'SENSE', 'WE', 'OFTEN', 'TALK', '<end>']\n",
      "Predicted : them together into new forms and we create something new that's really where innovation <end>  || True ['<start>', 'OF', 'PROTECTING', 'INTELLECTUAL', 'PROPERTY', 'YOU', 'KNOW', 'BUILDING', 'BARRICADES', '<end>']\n",
      "Predicted : a lot of these values and it's just wonderful kind of tale of innovation and how it happens in unlikely <end>  || True ['<start>', 'IDEAS', 'AND', 'THE', 'CULTURE', 'WILL', 'BE', 'MORE', 'INNOVATIVE', 'BUT', 'I', 'THINK', \"THERE'S\", 'A', 'CASE', 'TO', 'BE', 'MADE', 'THAT', 'WE', 'SHOULD', 'SPEND', 'AT', 'LEAST', 'AS', 'MUCH', 'TIME', 'IF', '<end>']\n",
      "Predicted : that in fact the kind of equipment and <end>  || True ['<start>', 'A', 'LOT', 'OF', 'THESE', 'VALUES', 'AND', \"IT'S\", 'JUST', 'WONDERFUL', 'KIND', 'OF', 'TALE', 'OF', 'INNOVATION', 'AND', 'HOW', 'IT', 'HAPPENS', 'IN', 'UNLIKELY', '<end>']\n",
      "Predicted : morning and the news has just broken about this satellite that's now orbiting the planet from a known location on the planet from a known location on the planet from a known location on the planet from a known location on the planet from a known location on the planet from a  || True ['<start>', 'MORNING', 'AND', 'THE', 'NEWS', 'HAS', 'JUST', 'BROKEN', 'ABOUT', 'THIS', 'SATELLITE', \"THAT'S\", 'NOW', 'ORBITING', 'THE', 'PLANET', 'AND', 'OF', 'COURSE', 'THIS', 'IS', 'NERD', 'HEAVEN', 'RIGHT', 'THERE', 'ARE', 'ALL', '<end>']\n",
      "Predicted : morning and the news has just broken about this satellite that's now orbiting the planet from a known location on the planet from a known location on the planet from a known location on the planet from a known location on the planet from a known location on the planet from a  || True ['<start>', 'GEEKS', 'WHO', 'ARE', 'THERE', 'THINKING', 'OH', 'MY', 'GOSH', 'THIS', 'IS', 'INCREDIBLE', 'I', \"CAN'T\", 'BELIEVE', 'THIS', 'HAS', 'HAPPENED', 'AND', 'TWO', 'OF', 'THEM', 'TWO', '20', 'SOMETHING', 'RESEARCHERS', 'AT', 'THE', 'APL', 'ARE', '<end>']\n",
      "Predicted : at the cafeteria table having an informal conversation with a bunch of their colleagues and weiffenbach and they start talking and weiffenbach and they start talking and weiffenbach and they start talking and weiffenbach and they start talking and weiffenbach and they start talking and weiffenbach and they start talking and weiffenbach  || True ['<start>', 'AT', 'THE', 'CAFETERIA', 'TABLE', 'HAVING', 'AN', 'INFORMAL', 'CONVERSATION', 'WITH', 'A', 'BUNCH', 'OF', 'THEIR', 'COLLEAGUES', 'AND', 'THESE', 'TWO', 'GUYS', 'ARE', 'NAMED', 'GUIER', 'AND', 'WEIFFENBACH', 'AND', 'THEY', 'START', 'TALKING', 'AND', 'ONE', 'OF', 'THEM', 'SAYS', 'HEY', 'HAS', 'ANYBODY', 'TRIED', 'TO', 'LISTEN', 'FOR', 'THIS', 'THING', \"THERE'S\", 'THIS', '<end>']\n",
      "Predicted : that there's an interesting problem but they don't quite have the tools yet to discover them they spend all this time <end>  || True ['<start>', 'OF', 'THEIR', 'COLLEAGUES', 'AND', \"EVERYBODY'S\", 'LIKE', 'NO', 'I', \"HADN'T\", 'THOUGHT', 'OF', 'DOING', 'THAT', \"THAT'S\", 'AN', 'INTERESTING', 'IDEA', 'AND', 'IT', 'TURNS', '<end>']\n",
      "Predicted : and see what are the abundant resources in all a lot of keeping their cars on the signal because the soviets made sputnik very easy to <end>  || True ['<start>', 'IS', 'KIND', 'OF', 'AN', 'EXPERT', 'IN', 'MICROWAVE', 'RECEPTION', 'AND', \"HE'S\", 'GOT', 'A', 'LITTLE', 'ANTENNAE', 'SET', 'UP', 'WITH', 'AN', 'AMPLIFIER', 'IN', 'HIS', 'OFFICE', 'AND', 'SO', 'GUIER', 'AND', 'WEIFFENBACH', 'GO', 'BACK', 'TO', \"WEIFFENBACH'S\", 'OFFICE', 'AND', 'THEY', 'START', 'KIND', 'OF', 'NOODLING', 'AROUND', 'HACKING', 'AS', 'WE', 'MIGHT', 'CALL', 'IT', 'NOW', '<end>']\n",
      "Predicted : couple of their job description they run some more of the apl they run some more of the apl they run some more of the apl they run some more of the apl they run some more of the apl they run some more of the apl they run some more of  || True ['<start>', 'COUPLE', 'OF', 'HOURS', 'THEY', 'ACTUALLY', 'START', 'PICKING', 'UP', 'THE', 'SIGNAL', 'BECAUSE', 'THE', 'SOVIETS', 'MADE', 'SPUTNIK', 'VERY', 'EASY', 'TO', 'TRACK', 'IT', 'WAS', 'RIGHT', 'AT', '20', 'MHZ', 'SO', 'YOU', 'COULD', 'PICK', 'IT', 'UP', 'REALLY', 'EASILY', 'BECAUSE', 'THEY', 'WERE', 'AFRAID', 'THAT', 'PEOPLE', 'WOULD', 'THINK', 'IT', 'WAS', 'HOAX', 'BASICALLY', 'SO', 'THEY', 'MADE', 'IT', 'REALLY', 'EASY', 'TO', '<end>']\n",
      "Predicted : a bunch of satellites and use it to track our submarines and figure out their location in the middle of the ocean could you work on that <end>  || True ['<start>', 'IS', 'KIND', 'OF', 'HISTORIC', 'WE', 'MAY', 'BE', 'THE', 'FIRST', 'PEOPLE', 'IN', 'THE', 'UNITED', 'STATES', 'TO', 'BE', 'LISTENING', 'TO', 'THIS', 'WE', 'SHOULD', 'RECORD', 'IT', 'AND', 'SO', 'THEY', 'BRING', 'IN', 'THIS', 'BIG', 'CLUNKY', 'ANALOG', 'TAPE', 'RECORDER', 'AND', '<end>']\n",
      "Predicted : these little bit of their job so when they were doing every little bleep bleeps and they they start thinking well gosh you know we're noticing small <end>  || True ['<start>', 'THESE', 'LITTLE', 'BLEEP', 'BLEEPS', 'AND', 'THEY', 'START', 'WRITING', 'THE', 'KIND', 'OF', 'DATE', 'STAMP', 'TIME', 'STAMPS', 'FOR', 'EACH', 'LITTLE', 'BLEEP', 'THAT', 'THEY', 'RECORD', 'AND', 'THEY', 'THEY', 'START', 'THINKING', 'WELL', 'GOSH', 'YOU', 'KNOW', \"WE'RE\", 'NOTICING', 'SMALL', '<end>']\n",
      "Predicted : of different ideas that are together different backgrounds different interests jostling with each other bouncing off each other that environment is in fact the environment that leads to <end>  || True ['<start>', 'VARIATIONS', 'HERE', 'WE', 'COULD', 'PROBABLY', 'CALCULATE', 'THE', 'SPEED', 'THAT', 'THE', 'SATELLITE', 'IS', 'TRAVELING', 'IF', 'WE', 'DO', 'LITTLE', 'BASIC', 'MATH', 'HERE', 'USING', 'THE', 'DOPPLER', '<end>']\n",
      "Predicted : of different ideas that are together different backgrounds different interests jostling with each other bouncing off each other that environment is in fact the environment that leads to <end>  || True ['<start>', 'WE', 'COULD', 'ACTUALLY', 'TAKE', 'A', 'LOOK', 'AT', 'THE', 'SLOPE', 'OF', 'THE', 'DOPPLER', 'EFFECT', 'TO', 'FIGURE', 'OUT', 'THE', 'POINTS', 'AT', 'WHICH', 'THE', 'SATELLITE', 'IS', 'CLOSEST', 'TO', 'OUR', 'ANTENNAE', 'AND', 'THE', 'POINTS', 'AT', 'WHICH', \"IT'S\", 'FARTHEST', 'AWAY', \"THAT'S\", 'PRETTY', 'COOL', '<end>']\n",
      "Predicted : they don't have a little side project that hadn't been officially part of their job description they get permission this is all a little side project that hadn't been officially part of their job description they get permission this is all a little side project that hadn't been officially part of their  || True ['<start>', 'THEY', 'GET', 'PERMISSION', 'THIS', 'IS', 'ALL', 'A', 'LITTLE', 'SIDE', 'PROJECT', 'THAT', \"HADN'T\", 'BEEN', 'OFFICIALLY', 'PART', 'OF', 'THEIR', 'JOB', 'DESCRIPTION', 'THEY', 'GET', 'PERMISSION', 'TO', 'USE', 'THE', 'NEW', 'YOU', 'KNOW', 'UNIVAC', 'COMPUTER', 'THAT', 'TAKES', 'UP', 'AN', 'ENTIRE', 'ROOM', 'THAT', \"THEY'D\", 'JUST', 'GOTTEN', 'AT', 'THE', 'APL', 'THEY', 'RUN', 'SOME', 'MORE', 'OF', 'THE', 'NUMBERS', '<end>']\n",
      "Predicted : is that darwin in a sense had the idea he had the concept but was unable of fully thinking it yet and that is actually how great ideas often <end>  || True ['<start>', 'ABOUT', 'THREE', 'OR', 'FOUR', 'WEEKS', 'TURNS', 'OUT', 'THEY', 'HAVE', 'MAPPED', 'THE', 'EXACT', 'TRAJECTORY', 'OF', 'THIS', 'SATELLITE', 'AROUND', 'THE', 'EARTH', 'JUST', 'FROM', 'LISTENING', 'TO', 'THIS', 'ONE', 'LITTLE', 'SIGNAL', 'GOING', 'OFF', 'ON', 'THIS', 'LITTLE', 'SIDE', '<end>']\n",
      "Predicted : morning and the news has just broken about this satellite that's now orbiting the planet from a known location on the planet from a known location on the planet from a known location on the planet from a known location on the planet from a known location on the planet from a  || True ['<start>', 'ON', \"YOU'VE\", 'FIGURED', 'OUT', 'AN', 'UNKNOWN', 'LOCATION', 'OF', 'SATELLITE', 'ORBITING', 'THE', 'PLANET', 'FROM', 'A', 'KNOWN', 'LOCATION', 'ON', 'THE', 'GROUND', '<end>']\n",
      "Predicted : is that darwin in a sense had the idea he had the concept but was unable of fully thinking it yet and that is actually how great ideas often <end>  || True ['<start>', 'THE', 'OTHER', 'WAY', 'COULD', 'YOU', 'FIGURE', 'OUT', 'AN', 'UNKNOWN', 'LOCATION', 'ON', 'THE', 'GROUND', 'IF', 'YOU', 'KNEW', 'THE', 'LOCATION', 'OF', 'THE', 'SATELLITE', 'AND', 'THEY', 'THOUGHT', 'ABOUT', 'IT', 'AND', 'THEY', 'SAID', 'WELL', 'I', 'GUESS', 'MAYBE', 'YOU', 'COULD', '<end>']\n",
      "Predicted : a lot of these values and it's just wonderful kind of tale of innovation and how it happens in unlikely <end>  || True ['<start>', 'SAID', 'OH', \"THAT'S\", 'GREAT', 'BECAUSE', 'SEE', 'I', 'HAVE', 'THESE', 'NEW', 'NUCLEAR', 'SUBMARINES', 'THAT', \"I'M\", 'BUILDING', 'AND', '<end>']\n",
      "Predicted : a bunch of satellites and use it to track our submarines and figure out their location in the middle of the ocean could you work on that <end>  || True ['<start>', 'A', 'BUNCH', 'OF', 'SATELLITES', 'AND', 'USE', 'IT', 'TO', 'TRACK', 'OUR', 'SUBMARINES', 'AND', 'FIGURE', 'OUT', 'THEIR', 'LOCATION', 'IN', 'THE', 'MIDDLE', 'OF', 'THE', 'OCEAN', 'COULD', 'YOU', 'WORK', 'ON', 'THAT', '<end>']\n",
      "Predicted : if not more has used said device and said satellite system to locate a nearby coffeehouse somewhere in the last {lg} in all the last {lg} in all the last {lg} in all the last {lg} in all the last {lg} in all the last {lg} in all the last {lg} in  || True ['<start>', 'IF', 'NOT', 'MORE', 'HAS', 'USED', 'SAID', 'DEVICE', 'AND', 'SAID', 'SATELLITE', 'SYSTEM', 'TO', 'LOCATE', 'A', 'NEARBY', 'COFFEEHOUSE', 'SOMEWHERE', 'IN', 'THE', 'LAST', '{LG}', 'IN', 'THE', 'LAST', 'DAY', 'OR', 'LAST', 'WEEK', '<end>']\n",
      "Predicted : even dreamed of mean here you have these guys who basically thought they were fighting the cold war <end>  || True ['<start>', 'EVEN', 'DREAMED', 'OF', 'MEAN', 'HERE', 'YOU', 'HAVE', 'THESE', 'GUYS', 'WHO', 'BASICALLY', 'THOUGHT', 'THEY', 'WERE', 'JUST', 'FOLLOWING', 'THIS', 'HUNCH', 'THIS', 'LITTLE', 'PASSION', 'THAT', 'HAD', 'DEVELOPED', 'THEN', 'THEY', 'THOUGHT', 'THEY', 'WERE', 'FIGHTING', 'THE', 'COLD', 'WAR', '<end>']\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(video_files)):\n",
    "  print(\"Predicted :\",evaluate(X_train[i]),end=\"\")\n",
    "  print(\" || True\",sent[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "id": "xdMfIb9T9MAE",
    "outputId": "ff9c3e02-4309-42b8-cb5c-b8147f02e7e8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"forerunner on the expertise to think could we build a neonatal incubator that's built entirely out of automobile <end> \""
      ]
     },
     "execution_count": 54,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate(X_train[20]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 646
    },
    "id": "AfAAbOuw2nm7",
    "outputId": "1dd04799-187f-4217-e16b-3945e9ee23f8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<start>',\n",
       " 'FORERUNNER',\n",
       " 'ON',\n",
       " 'THE',\n",
       " 'STREET',\n",
       " 'IN',\n",
       " 'ALL',\n",
       " 'THESE',\n",
       " 'PLACES',\n",
       " 'THEY',\n",
       " 'SEEM',\n",
       " 'TO',\n",
       " 'HAVE',\n",
       " 'THE',\n",
       " 'EXPERTISE',\n",
       " 'TO',\n",
       " 'KEEP',\n",
       " 'CARS',\n",
       " 'WORKING',\n",
       " 'SO',\n",
       " 'THEY',\n",
       " 'STARTED',\n",
       " 'TO',\n",
       " 'THINK',\n",
       " 'COULD',\n",
       " 'WE',\n",
       " 'BUILD',\n",
       " 'A',\n",
       " 'NEONATAL',\n",
       " 'INCUBATOR',\n",
       " \"THAT'S\",\n",
       " 'BUILT',\n",
       " 'ENTIRELY',\n",
       " 'OUT',\n",
       " 'OF',\n",
       " 'AUTOMOBILE',\n",
       " '<end>']"
      ]
     },
     "execution_count": 56,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent[20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "id": "639TW9AUxh_D",
    "outputId": "35ec4206-274a-4e94-b334-d034bb3132ef"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"spending a lot of time thinking about coffeehouses for the last five years because i've been kind of on this quest to investigate this <end> \""
      ]
     },
     "execution_count": 57,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate(X_train[5]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 459
    },
    "id": "JvHJJTEzxnLg",
    "outputId": "b1319a51-e071-4d37-ac86-cc031c34d857"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<start>',\n",
       " 'SPENDING',\n",
       " 'A',\n",
       " 'LOT',\n",
       " 'OF',\n",
       " 'TIME',\n",
       " 'THINKING',\n",
       " 'ABOUT',\n",
       " 'COFFEEHOUSES',\n",
       " 'FOR',\n",
       " 'THE',\n",
       " 'LAST',\n",
       " 'FIVE',\n",
       " 'YEARS',\n",
       " 'BECAUSE',\n",
       " \"I'VE\",\n",
       " 'BEEN',\n",
       " 'KIND',\n",
       " 'OF',\n",
       " 'ON',\n",
       " 'THIS',\n",
       " 'QUEST',\n",
       " 'TO',\n",
       " 'INVESTIGATE',\n",
       " 'THIS',\n",
       " '<end>']"
      ]
     },
     "execution_count": 58,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kFA6yWu3NkkR"
   },
   "outputs": [],
   "source": [
    "!cp -r '/content/training_checkpoints' '/gdrive/My Drive/Hello Attention/Practice 4/CKPT'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XI0qEUkyTKg_"
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# saving\n",
    "with open('tokenizer.pickle', 'wb') as handle:\n",
    "    pickle.dump(tokenizer, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "    \n",
    "# loading\n",
    "#with open('tokenizer.pickle', 'rb') as handle:\n",
    "#    tokenizer = pickle.load(handle)'''import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3pNEukM5TYj5"
   },
   "outputs": [],
   "source": [
    "with open('tokenizer.pickle', 'rb') as handle:\n",
    "    tokenizer = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "x8gaj9BvTnJX",
    "outputId": "002aec03-8a64-4e09-a9dc-ece4a3fab279"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras_preprocessing.text.Tokenizer at 0x7f6313955278>"
      ]
     },
     "execution_count": 63,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lgDoEn_nUKK8"
   },
   "outputs": [],
   "source": [
    "!cp -r '/content/tokenizer.pickle' '/gdrive/My Drive/Hello Attention/Practice 4/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Th6kBBoQ2oFe"
   },
   "source": [
    "#Rough"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 126
    },
    "id": "TegzMbJsdzZS",
    "outputId": "f5bb1f7d-f88e-4770-eb42-a641b63e1ec2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "tf.Tensor([0.654902  0.5882353 0.4509804], shape=(3,), dtype=float32)\n",
      "[0.654902  0.5882353 0.4509804]\n",
      "0\n",
      "tf.Tensor([0.654902  0.5882353 0.4509804], shape=(3,), dtype=float32)\n",
      "[0.654902  0.5882353 0.4509804]\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(2):\n",
    "    start = time.time()\n",
    "    hidden = encoder.initialize_hidden_state()\n",
    "    total_loss = 0\n",
    "    \n",
    "    for (batch, (img_tensor, target)) in enumerate(dataset):\n",
    "      print(batch)\n",
    "      print(img_tensor[0][0][0][0])\n",
    "      print(X_train[0][0][0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "kCUrG6Gualv9",
    "outputId": "8783f2ea-1377-47d2-87fa-083f4fb7e5a7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(75, 100, 50, 3)"
      ]
     },
     "execution_count": 138,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "0QcKPfQebTsx",
    "outputId": "34de0d30-190d-4c8a-8a94-054c1d21a2af"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2]])"
      ]
     },
     "execution_count": 141,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.expand_dims([tokenizer.word_index['<start>']], 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MADNlMRRbHYG"
   },
   "outputs": [],
   "source": [
    "max_length=6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-ciI0BRec2w0"
   },
   "outputs": [],
   "source": [
    "hidden = [tf.zeros((1, units))]\n",
    "enc_out, enc_hidden = encoder(X_train[0], hidden)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 55
    },
    "id": "JWHM5jHugkOz",
    "outputId": "31303322-1a4a-4a47-a407-b94946500225"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=360999, shape=(3,), dtype=float32, numpy=array([0.654902 , 0.5882353, 0.4509804], dtype=float32)>"
      ]
     },
     "execution_count": 161,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.convert_to_tensor(X_train[0][0][0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tRew0MwLJSrp"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "vBbF2NvgckVv",
    "outputId": "a12909bb-1828-4fc1-a9d6-38ef398859c6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'set white with <end> '"
      ]
     },
     "execution_count": 180,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate(X_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "id": "_K6nsEJecnIp",
    "outputId": "dd019ea4-9953-4af7-db92-a2feefcc29eb"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['<start>', 'set', 'white', 'with', 'p', 'two', 'soon', '<end>'],\n",
       " ['<start>', 'place', 'red', 'in', 'a', 'zero', 'now', '<end>']]"
      ]
     },
     "execution_count": 178,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4pjCrSvo09Z_"
   },
   "outputs": [],
   "source": [
    "ypred = []\n",
    "for i in range(32):\n",
    "  ypred.append(evaluate(X_test[i]))\n",
    "with open('ypred.txt', 'w') as f:\n",
    "  print('\\n'.join(ypred), file=f)\n",
    "!cp 'ypred.txt' 'drive/My Drive/ypred.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RzRnp_522919"
   },
   "outputs": [],
   "source": [
    "y = []\n",
    "for i in range(32):\n",
    "  ypred.append(evaluate(X_test[i]))\n",
    "with open('ypred.txt', 'w') as f:\n",
    "  print('\\n'.join(ypred), file=f)\n",
    "!cp 'ypred.txt' 'drive/My Drive/ypred.txt'"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "6ftV0POaPXlH",
    "og1MyyIhsqVL",
    "y7Hkb3FAyjHQ",
    "LFKwLwaFmikV",
    "Th6kBBoQ2oFe"
   ],
   "name": "demo.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
